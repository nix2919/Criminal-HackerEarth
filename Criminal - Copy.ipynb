{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean, nan, inf\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold, SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IFATHER      float64\n",
       "NRCH17_2     float64\n",
       "IRHHSIZ2     float64\n",
       "IIHHSIZ2     float64\n",
       "IRKI17_2     float64\n",
       "IIKI17_2     float64\n",
       "IRHH65_2     float64\n",
       "IIHH65_2     float64\n",
       "PRXRETRY     float64\n",
       "PRXYDATA     float64\n",
       "MEDICARE     float64\n",
       "CAIDCHIP     float64\n",
       "CHAMPUS      float64\n",
       "PRVHLTIN     float64\n",
       "GRPHLTIN     float64\n",
       "HLTINNOS     float64\n",
       "HLCNOTYR     float64\n",
       "HLCNOTMO     float64\n",
       "HLCLAST      float64\n",
       "HLLOSRSN     float64\n",
       "HLNVCOST     float64\n",
       "HLNVOFFR     float64\n",
       "HLNVREF      float64\n",
       "HLNVNEED     float64\n",
       "HLNVSOR      float64\n",
       "IRMCDCHP     float64\n",
       "IIMCDCHP     float64\n",
       "IRMEDICR     float64\n",
       "IIMEDICR     float64\n",
       "IRCHMPUS     float64\n",
       "              ...   \n",
       "CELLNOTCL    float64\n",
       "CELLWRKNG    float64\n",
       "IRFAMSOC     float64\n",
       "IIFAMSOC     float64\n",
       "IRFAMSSI     float64\n",
       "IIFAMSSI     float64\n",
       "IRFSTAMP     float64\n",
       "IIFSTAMP     float64\n",
       "IRFAMPMT     float64\n",
       "IIFAMPMT     float64\n",
       "IRFAMSVC     float64\n",
       "IIFAMSVC     float64\n",
       "IRWELMOS     float64\n",
       "IIWELMOS     float64\n",
       "IRPINC3      float64\n",
       "IRFAMIN3     float64\n",
       "IIPINC3      float64\n",
       "IIFAMIN3     float64\n",
       "GOVTPROG     float64\n",
       "POVERTY3     float64\n",
       "TOOLONG      float64\n",
       "TROUBUND     float64\n",
       "PDEN10       float64\n",
       "COUTYP2      float64\n",
       "MAIIN102     float64\n",
       "AIIND102     float64\n",
       "ANALWT_C     float64\n",
       "VESTR        float64\n",
       "VEREP        float64\n",
       "Criminal       int64\n",
       "Length: 71, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "train = train.replace([inf, -inf], nan).dropna().reset_index(drop=True)\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "IFATHER 4\n",
      "NRCH17_2 4\n",
      "IRHHSIZ2 6\n",
      "IIHHSIZ2 1\n",
      "IRKI17_2 4\n",
      "IIKI17_2 2\n",
      "IRHH65_2 3\n",
      "IIHH65_2 3\n",
      "PRXRETRY 5\n",
      "PRXYDATA 6\n",
      "MEDICARE 5\n",
      "CAIDCHIP 5\n",
      "CHAMPUS 5\n",
      "PRVHLTIN 5\n",
      "GRPHLTIN 7\n",
      "HLTINNOS 5\n",
      "HLCNOTYR 7\n",
      "HLCNOTMO 17\n",
      "HLCLAST 9\n",
      "HLLOSRSN 17\n",
      "HLNVCOST 6\n",
      "HLNVOFFR 6\n",
      "HLNVREF 6\n",
      "HLNVNEED 6\n",
      "HLNVSOR 6\n",
      "IRMCDCHP 2\n",
      "IIMCDCHP 2\n",
      "IRMEDICR 2\n",
      "IIMEDICR 2\n",
      "IRCHMPUS 2\n",
      "IICHMPUS 2\n",
      "IRPRVHLT 2\n",
      "IIPRVHLT 2\n",
      "IROTHHLT 3\n",
      "IIOTHHLT 3\n",
      "HLCALLFG 2\n",
      "HLCALL99 2\n",
      "ANYHLTI2 5\n",
      "IRINSUR4 2\n",
      "IIINSUR4 2\n",
      "OTHINS 2\n",
      "CELLNOTCL 6\n",
      "CELLWRKNG 6\n",
      "IRFAMSOC 2\n",
      "IIFAMSOC 2\n",
      "IRFAMSSI 2\n",
      "IIFAMSSI 2\n",
      "IRFSTAMP 2\n",
      "IIFSTAMP 2\n",
      "IRFAMPMT 2\n",
      "IIFAMPMT 2\n",
      "IRFAMSVC 2\n",
      "IIFAMSVC 2\n",
      "IRWELMOS 13\n",
      "IIWELMOS 3\n",
      "IRPINC3 7\n",
      "IRFAMIN3 7\n",
      "IIPINC3 2\n",
      "IIFAMIN3 2\n",
      "GOVTPROG 2\n",
      "POVERTY3 3\n",
      "TOOLONG 3\n",
      "TROUBUND 3\n",
      "PDEN10 3\n",
      "COUTYP2 3\n",
      "MAIIN102 2\n",
      "AIIND102 2\n",
      "ANALWT_C 45250\n",
      "VESTR 50\n",
      "VEREP 2\n",
      "Criminal 2\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "for col in cols:\n",
    "    print(col, len(train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NRCH17_2', 'IRHHSIZ2', 'IRKI17_2', 'IRHH65_2', 'HLCNOTMO', 'HLCLAST', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 8 62\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
=======
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFATHER\n",
      "IIHHSIZ2\n",
      "IIKI17_2\n",
      "IIHH65_2\n",
      "PRXRETRY\n",
      "PRXYDATA\n",
      "MEDICARE\n",
      "CAIDCHIP\n",
      "CHAMPUS\n",
      "PRVHLTIN\n",
      "GRPHLTIN\n",
      "HLTINNOS\n",
      "HLCNOTYR\n",
      "HLLOSRSN\n",
      "HLNVCOST\n",
      "HLNVOFFR\n",
      "HLNVREF\n",
      "HLNVNEED\n",
      "HLNVSOR\n",
      "IRMCDCHP\n",
      "IIMCDCHP\n",
      "IRMEDICR\n",
      "IIMEDICR\n",
      "IRCHMPUS\n",
      "IICHMPUS\n",
      "IRPRVHLT\n",
      "IIPRVHLT\n",
      "IROTHHLT\n",
      "IIOTHHLT\n",
      "HLCALLFG\n",
      "HLCALL99\n",
      "ANYHLTI2\n",
      "IRINSUR4\n",
      "IIINSUR4\n",
      "OTHINS\n",
      "CELLNOTCL\n",
      "CELLWRKNG\n",
      "IRFAMSOC\n",
      "IIFAMSOC\n",
      "IRFAMSSI\n",
      "IIFAMSSI\n",
      "IRFSTAMP\n",
      "IIFSTAMP\n",
      "IRFAMPMT\n",
      "IIFAMPMT\n",
      "IRFAMSVC\n",
      "IIFAMSVC\n",
      "IIWELMOS\n",
      "IRPINC3\n",
      "IRFAMIN3\n",
      "IIPINC3\n",
      "IIFAMIN3\n",
      "GOVTPROG\n",
      "POVERTY3\n",
      "TOOLONG\n",
      "TROUBUND\n",
      "PDEN10\n",
      "COUTYP2\n",
      "MAIIN102\n",
      "AIIND102\n",
      "VESTR\n",
      "VEREP\n"
     ]
    }
   ],
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].astype('category',copy=False)\n",
    "    '''\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i) for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)\n",
    "    '''\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHHSIZ2</th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>HLCNOTMO</th>\n",
       "      <th>HLCLAST</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>IFATHER_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>VESTR_40043.0</th>\n",
       "      <th>VESTR_40044.0</th>\n",
       "      <th>VESTR_40045.0</th>\n",
       "      <th>VESTR_40046.0</th>\n",
       "      <th>VESTR_40047.0</th>\n",
       "      <th>VESTR_40048.0</th>\n",
       "      <th>VESTR_40049.0</th>\n",
       "      <th>VESTR_40050.0</th>\n",
       "      <th>VEREP_1.0</th>\n",
       "      <th>VEREP_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NRCH17_2  IRHHSIZ2  IRKI17_2  IRHH65_2  HLCNOTMO  HLCLAST  IRWELMOS  \\\n",
       "0       2.0       4.0       3.0       1.0      99.0     99.0      99.0   \n",
       "1       1.0       3.0       2.0       1.0      99.0     99.0      99.0   \n",
       "\n",
       "      ANALWT_C  Criminal  IFATHER_1.0    ...      VESTR_40043.0  \\\n",
       "0  3884.805998         0            0    ...                  0   \n",
       "1  1627.108106         1            0    ...                  0   \n",
       "\n",
       "   VESTR_40044.0  VESTR_40045.0  VESTR_40046.0  VESTR_40047.0  VESTR_40048.0  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "\n",
       "   VESTR_40049.0  VESTR_40050.0  VEREP_1.0  VEREP_2.0  \n",
       "0              0              0          1          0  \n",
       "1              0              0          0          1  \n",
       "\n",
       "[2 rows x 279 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 10,
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
<<<<<<< HEAD
   "execution_count": 9,
>>>>>>> 1f0e35c6fa980bef174c31044acf1809c7ef542b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(27175, 278) (18118, 278)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.4, random_state=11)\n",
    "print(X_train.shape, X_test.shape)"
=======
      "(31705, 70) (13588, 70)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=11)\n",
    "print(X_train.shape, X_test.shape)"
=======
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.4, random_state=11)"
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
>>>>>>> 1f0e35c6fa980bef174c31044acf1809c7ef542b
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(norm_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(norm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier()#n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp[:20].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(12,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_feats = list(feat_imp[:20].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
>>>>>>> 1f0e35c6fa980bef174c31044acf1809c7ef542b
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=et)\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "rfe = RFE(rf, step=0.25)\n",
    "select = SelectFromModel(rf)\n",
    "kbest = SelectKBest(chi2)\n",
    "\n",
    "pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "\n",
    "feat_sel_params = [\n",
    "    {\n",
    "        'feat_sel': [kbest],\n",
    "        'feat_sel__k': [20, 30]},\n",
    "    {\n",
    "        'feat_sel': [rfe],\n",
    "        'feat_sel__estimator': [ada], #rf, et, \n",
    "        'feat_sel__n_features_to_select': [20]},\n",
    "    {\n",
    "        'feat_sel': [select],\n",
    "        'feat_sel__estimator': [ada], #rf, et,\n",
    "        'feat_sel__threshold': ['1.5*mean', '2*mean']}\n",
    "]\n",
    "\n",
    "model_params = [\n",
    "    {\n",
    "        'model': [gb],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.05]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "    {\n",
    "        'model': [ada],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.05], #0.01, 0.04, 0.1, 0.5, 1\n",
    "        'model__random_state': [2]},\n",
    "    {\n",
    "        'model': [rf],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7, 9\n",
    "        'model__max_depth': [9]}, #8, 10, 14\n",
    "    {\n",
    "        'model': [et],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7\n",
    "        'model__max_depth': [9]} #8, 10, 14\n",
    "]\n",
    "\n",
    "params = []\n",
    "for feat_sel in feat_sel_params:\n",
    "    for model in model_params:\n",
    "        # Merge dictionaries and append to list\n",
    "        params.append({**feat_sel, **model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.any(np.isnan(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
=======
   "metadata": {
    "scrolled": true
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  5.6min\n"
     ]
    }
   ],
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
>>>>>>> 1f0e35c6fa980bef174c31044acf1809c7ef542b
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "metadata": {
    "collapsed": true
   },
=======
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "# imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].support_]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[imp_feats].head(1)"
=======
   "metadata": {},
>>>>>>> 1f0e35c6fa980bef174c31044acf1809c7ef542b
   "outputs": [],
   "source": [
    "imp_feats = X-train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
>>>>>>> 7b371a7d2d2ddc6c9a415c1d39e8f1b44dd15034
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def mccscorer(y_true, y_pred):\n",
    "    return matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic', eval_metric=mccscorer)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.02, 0.05],   # Learning rate alpha\n",
    "    'max_depth': [7, 9, 11],   # maximum depth of the tree\n",
    "    'gamma': [0.2, 0.5, 1],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [3, 6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [100],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=3, verbose=20, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train) # [imp_feats]\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''imp_feats = X_train.columns.values[grid.get_params]\n",
    "# imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].support_]\n",
    "print(imp_feats)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "best_model = grid.best_estimator_.fit(X_train, y_train) #[imp_feats]\n",
    "pred = best_model.predict(X_test) #[imp_feats]\n",
    "print('MCC:', matthews_corrcoef(y_test, pred))\n",
    "print('Acc:', accuracy_score(y_test, pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    'num_class': 2\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    print(len(preds), len(labels))\n",
    "    thresholds = np.linspace(0.01, 0.99, 50)\n",
    "    mcc = np.array([matthews_corrcoef(labels, preds>thr) for thr in thresholds])\n",
    "    best_score = mcc.max()\n",
    "    return 'error', -best_score\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, feval=evalerror, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
