{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold, SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA',\n",
       "       'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN',\n",
       "       'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN',\n",
       "       'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR',\n",
       "       'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS',\n",
       "       'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4',\n",
       "       'OTHINS', 'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC',\n",
       "       'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT',\n",
       "       'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS',\n",
       "       'IRPINC3', 'IRFAMIN3', 'IIPINC3', 'IIFAMIN3', 'GOVTPROG',\n",
       "       'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP2', 'MAIIN102',\n",
       "       'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP', 'Criminal'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "train = train.dropna()\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "IFATHER 4\n",
      "NRCH17_2 4\n",
      "IRHHSIZ2 6\n",
      "IIHHSIZ2 1\n",
      "IRKI17_2 4\n",
      "IIKI17_2 2\n",
      "IRHH65_2 3\n",
      "IIHH65_2 3\n",
      "PRXRETRY 5\n",
      "PRXYDATA 6\n",
      "MEDICARE 5\n",
      "CAIDCHIP 5\n",
      "CHAMPUS 5\n",
      "PRVHLTIN 5\n",
      "GRPHLTIN 7\n",
      "HLTINNOS 5\n",
      "HLCNOTYR 7\n",
      "HLCNOTMO 17\n",
      "HLCLAST 9\n",
      "HLLOSRSN 17\n",
      "HLNVCOST 6\n",
      "HLNVOFFR 6\n",
      "HLNVREF 6\n",
      "HLNVNEED 6\n",
      "HLNVSOR 6\n",
      "IRMCDCHP 2\n",
      "IIMCDCHP 2\n",
      "IRMEDICR 2\n",
      "IIMEDICR 2\n",
      "IRCHMPUS 2\n",
      "IICHMPUS 2\n",
      "IRPRVHLT 2\n",
      "IIPRVHLT 2\n",
      "IROTHHLT 3\n",
      "IIOTHHLT 3\n",
      "HLCALLFG 2\n",
      "HLCALL99 2\n",
      "ANYHLTI2 5\n",
      "IRINSUR4 2\n",
      "IIINSUR4 2\n",
      "OTHINS 2\n",
      "CELLNOTCL 6\n",
      "CELLWRKNG 6\n",
      "IRFAMSOC 2\n",
      "IIFAMSOC 2\n",
      "IRFAMSSI 2\n",
      "IIFAMSSI 2\n",
      "IRFSTAMP 2\n",
      "IIFSTAMP 2\n",
      "IRFAMPMT 2\n",
      "IIFAMPMT 2\n",
      "IRFAMSVC 2\n",
      "IIFAMSVC 2\n",
      "IRWELMOS 13\n",
      "IIWELMOS 3\n",
      "IRPINC3 7\n",
      "IRFAMIN3 7\n",
      "IIPINC3 2\n",
      "IIFAMIN3 2\n",
      "GOVTPROG 2\n",
      "POVERTY3 3\n",
      "TOOLONG 3\n",
      "TROUBUND 3\n",
      "PDEN10 3\n",
      "COUTYP2 3\n",
      "MAIIN102 2\n",
      "AIIND102 2\n",
      "ANALWT_C 45250\n",
      "VESTR 50\n",
      "VEREP 2\n",
      "Criminal 2\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "for col in cols:\n",
    "    print(col, len(train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NRCH17_2', 'IRHHSIZ2', 'IRKI17_2', 'IRHH65_2', 'HLCNOTMO', 'HLCLAST', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 8 62\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFATHER\n",
      "IIHHSIZ2\n",
      "IIKI17_2\n",
      "IIHH65_2\n",
      "PRXRETRY\n",
      "PRXYDATA\n",
      "MEDICARE\n",
      "CAIDCHIP\n",
      "CHAMPUS\n",
      "PRVHLTIN\n",
      "GRPHLTIN\n",
      "HLTINNOS\n",
      "HLCNOTYR\n",
      "HLLOSRSN\n",
      "HLNVCOST\n",
      "HLNVOFFR\n",
      "HLNVREF\n",
      "HLNVNEED\n",
      "HLNVSOR\n",
      "IRMCDCHP\n",
      "IIMCDCHP\n",
      "IRMEDICR\n",
      "IIMEDICR\n",
      "IRCHMPUS\n",
      "IICHMPUS\n",
      "IRPRVHLT\n",
      "IIPRVHLT\n",
      "IROTHHLT\n",
      "IIOTHHLT\n",
      "HLCALLFG\n",
      "HLCALL99\n",
      "ANYHLTI2\n",
      "IRINSUR4\n",
      "IIINSUR4\n",
      "OTHINS\n",
      "CELLNOTCL\n",
      "CELLWRKNG\n",
      "IRFAMSOC\n",
      "IIFAMSOC\n",
      "IRFAMSSI\n",
      "IIFAMSSI\n",
      "IRFSTAMP\n",
      "IIFSTAMP\n",
      "IRFAMPMT\n",
      "IIFAMPMT\n",
      "IRFAMSVC\n",
      "IIFAMSVC\n",
      "IIWELMOS\n",
      "IRPINC3\n",
      "IRFAMIN3\n",
      "IIPINC3\n",
      "IIFAMIN3\n",
      "GOVTPROG\n",
      "POVERTY3\n",
      "TOOLONG\n",
      "TROUBUND\n",
      "PDEN10\n",
      "COUTYP2\n",
      "MAIIN102\n",
      "AIIND102\n",
      "VESTR\n",
      "VEREP\n"
     ]
    }
   ],
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].astype('category',copy=False)\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i) for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NRCH17_2</th>\n",
       "      <th>IRHHSIZ2</th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>HLCNOTMO</th>\n",
       "      <th>HLCLAST</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>IFATHER_1.0</th>\n",
       "      <th>...</th>\n",
       "      <th>VESTR_40043.0</th>\n",
       "      <th>VESTR_40044.0</th>\n",
       "      <th>VESTR_40045.0</th>\n",
       "      <th>VESTR_40046.0</th>\n",
       "      <th>VESTR_40047.0</th>\n",
       "      <th>VESTR_40048.0</th>\n",
       "      <th>VESTR_40049.0</th>\n",
       "      <th>VESTR_40050.0</th>\n",
       "      <th>VEREP_1.0</th>\n",
       "      <th>VEREP_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NRCH17_2  IRHHSIZ2  IRKI17_2  IRHH65_2  HLCNOTMO  HLCLAST  IRWELMOS  \\\n",
       "0       2.0       4.0       3.0       1.0      99.0     99.0      99.0   \n",
       "1       1.0       3.0       2.0       1.0      99.0     99.0      99.0   \n",
       "\n",
       "      ANALWT_C  Criminal  IFATHER_1.0    ...      VESTR_40043.0  \\\n",
       "0  3884.805998         0            0    ...                  0   \n",
       "1  1627.108106         1            0    ...                  0   \n",
       "\n",
       "   VESTR_40044.0  VESTR_40045.0  VESTR_40046.0  VESTR_40047.0  VESTR_40048.0  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "\n",
       "   VESTR_40049.0  VESTR_40050.0  VEREP_1.0  VEREP_2.0  \n",
       "0              0              0          1          0  \n",
       "1              0              0          0          1  \n",
       "\n",
       "[2 rows x 279 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X['download_time'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27175, 278) (18118, 278)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.4, random_state=11)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(norm_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(norm_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier()#n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp[:20].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(12,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_feats = list(feat_imp[:20].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=et)\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "rfe = RFE(rf, step=0.2)\n",
    "select = SelectFromModel(rf)\n",
    "kbest = SelectKBest(chi2)\n",
    "\n",
    "pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "\n",
    "feat_sel_params = [\n",
    "    {\n",
    "        'feat_sel': [kbest],\n",
    "        'feat_sel__k': [20, 30]},\n",
    "    {\n",
    "        'feat_sel': [rfe],\n",
    "        'feat_sel__estimator': [ada], #rf, et, \n",
    "        'feat_sel__n_features_to_select': [20]},\n",
    "    {\n",
    "        'feat_sel': [select],\n",
    "        'feat_sel__estimator': [ada]} #rf, et, \n",
    "]\n",
    "\n",
    "model_params = [\n",
    "    {\n",
    "        'model': [gb],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.05]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "    {\n",
    "        'model': [ada],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.05], #0.01, 0.04, 0.1, 0.5, 1\n",
    "        'model__random_state': [2]},\n",
    "    {\n",
    "        'model': [rf],\n",
    "        'model__n_estimators': [10], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7, 9\n",
    "        'model__max_depth': [9]}, #8, 10, 14\n",
    "    {\n",
    "        'model': [et],\n",
    "        'model__n_estimators': [1000], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7\n",
    "        'model__max_depth': [9]} #8, 10, 14\n",
    "]\n",
    "\n",
    "params = []\n",
    "for feat_sel in feat_sel_params:\n",
    "    for model in model_params:\n",
    "        # Merge dictionaries and append to list\n",
    "        params.append({**feat_sel, **model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_feats = X-train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = grid.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic', eval_metric='error')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.01, 0.03],   # Learning rate alpha\n",
    "    'max_depth': [8, 10, 14],   # maximum depth of the tree\n",
    "    'gamma': [0.5, 1],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [1000],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=20, n_jobs=-1, refit=True)\n",
    "\n",
    "grid.fit(X_train[imp_feats], y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "pred = grid.predict(X_test[imp_feats])\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    'eval_metric': 'error', \n",
    "    'num_class': 2\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train[imp_feats], y_train)\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
