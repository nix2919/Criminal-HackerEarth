{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA',\n",
       "       'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN',\n",
       "       'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN',\n",
       "       'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR',\n",
       "       'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS',\n",
       "       'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4',\n",
       "       'OTHINS', 'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC',\n",
       "       'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT',\n",
       "       'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS',\n",
       "       'IRPINC3', 'IRFAMIN3', 'IIPINC3', 'IIFAMIN3', 'GOVTPROG',\n",
       "       'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP2', 'MAIIN102',\n",
       "       'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP', 'Criminal'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "from numpy import inf, nan\n",
    "train = train.replace([inf, -inf], nan).dropna()\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "\n",
      " IFATHER\n",
      "      Overall  Criminal\n",
      "4.0  0.760758  0.653922\n",
      "1.0  0.171726  0.200000\n",
      "2.0  0.067339  0.145425\n",
      "3.0  0.000177  0.000654\n",
      "\n",
      " NRCH17_2\n",
      "      Overall  Criminal\n",
      "0.0  0.731548  0.889869\n",
      "1.0  0.110370  0.051634\n",
      "2.0  0.101804  0.037582\n",
      "3.0  0.056278  0.020915\n",
      "\n",
      " IRHHSIZ2\n",
      "      Overall  Criminal\n",
      "1.0  0.078489  0.139869\n",
      "2.0  0.222639  0.267974\n",
      "3.0  0.223147  0.217320\n",
      "4.0  0.239309  0.191503\n",
      "5.0  0.136003  0.101634\n",
      "6.0  0.100413  0.081699\n",
      "\n",
      " IIHHSIZ2\n",
      "     Overall  Criminal\n",
      "1.0      1.0       1.0\n",
      "\n",
      " IRKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.417084  0.494771\n",
      "2.0  0.223015  0.191176\n",
      "3.0  0.210695  0.176797\n",
      "4.0  0.149206  0.137255\n",
      "\n",
      " IIKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.997726  0.997712\n",
      "3.0  0.002274  0.002288\n",
      "\n",
      " IRHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.878193  0.741503\n",
      "2.0  0.079725  0.149346\n",
      "3.0  0.042082  0.109150\n",
      "\n",
      " IIHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.995474  0.995425\n",
      "3.0  0.004018  0.004248\n",
      "2.0  0.000508  0.000327\n",
      "\n",
      " PRXRETRY\n",
      "       Overall  Criminal\n",
      "2.0   0.016603  0.014706\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000110       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.982359  0.983987\n",
      "\n",
      " PRXYDATA\n",
      "       Overall  Criminal\n",
      "1.0   0.288676  0.363399\n",
      "2.0   0.000839  0.000654\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000066       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.709492  0.634641\n",
      "\n",
      " MEDICARE\n",
      "       Overall  Criminal\n",
      "2.0   0.912106  0.750327\n",
      "1.0   0.083567  0.236601\n",
      "94.0  0.003466  0.010131\n",
      "97.0  0.000773  0.002288\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " CAIDCHIP\n",
      "       Overall  Criminal\n",
      "1.0   0.225377  0.092484\n",
      "2.0   0.765659  0.882353\n",
      "85.0  0.001126  0.001307\n",
      "94.0  0.006911  0.020588\n",
      "97.0  0.000927  0.003268\n",
      "\n",
      " CHAMPUS\n",
      "       Overall  Criminal\n",
      "2.0   0.959817  0.962418\n",
      "1.0   0.037931  0.028105\n",
      "94.0  0.001590  0.006863\n",
      "97.0  0.000574  0.001961\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " PRVHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.607644  0.962418\n",
      "2.0   0.385932       NaN\n",
      "85.0  0.000088  0.000654\n",
      "94.0  0.005431  0.033007\n",
      "97.0  0.000905  0.003922\n",
      "\n",
      " GRPHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.535712  0.731373\n",
      "2.0   0.070386  0.224183\n",
      "85.0  0.000066  0.000327\n",
      "94.0  0.001523  0.006536\n",
      "97.0  0.000927  0.004248\n",
      "98.0  0.005453  0.033333\n",
      "99.0  0.385932       NaN\n",
      "\n",
      " HLTINNOS\n",
      "       Overall  Criminal\n",
      "1.0   0.031175       NaN\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.000486       NaN\n",
      "97.0  0.000132       NaN\n",
      "99.0  0.866028       1.0\n",
      "\n",
      " HLCNOTYR\n",
      "       Overall  Criminal\n",
      "1.0   0.071777  0.054575\n",
      "2.0   0.815402  0.914706\n",
      "85.0  0.000464  0.000654\n",
      "94.0  0.001943  0.004902\n",
      "97.0  0.001170  0.003595\n",
      "98.0  0.007065  0.021569\n",
      "99.0  0.102179       NaN\n",
      "\n",
      " HLCLAST\n",
      "       Overall  Criminal\n",
      "1.0   0.019208       NaN\n",
      "2.0   0.012320       NaN\n",
      "3.0   0.021063       NaN\n",
      "4.0   0.028967       NaN\n",
      "5.0   0.019849       NaN\n",
      "94.0  0.000729       NaN\n",
      "97.0  0.001192  0.003268\n",
      "98.0  0.007529  0.022222\n",
      "99.0  0.889144  0.974510\n",
      "\n",
      " HLNVCOST\n",
      "       Overall  Criminal\n",
      "1.0   0.009913       NaN\n",
      "6.0   0.009869       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVOFFR\n",
      "       Overall  Criminal\n",
      "1.0   0.002914       NaN\n",
      "6.0   0.016868       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVREF\n",
      "       Overall  Criminal\n",
      "1.0   0.000596       NaN\n",
      "6.0   0.019186       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVNEED\n",
      "       Overall  Criminal\n",
      "1.0   0.003974       NaN\n",
      "6.0   0.015808       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVSOR\n",
      "       Overall  Criminal\n",
      "1.0   0.002936       NaN\n",
      "6.0   0.016846       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " IRMCDCHP\n",
      "     Overall  Criminal\n",
      "2.0  0.77151  0.895425\n",
      "1.0  0.22849  0.104575\n",
      "\n",
      " IIMCDCHP\n",
      "      Overall  Criminal\n",
      "1.0  0.991036  0.974837\n",
      "3.0  0.008964  0.025163\n",
      "\n",
      " IRMEDICR\n",
      "      Overall  Criminal\n",
      "2.0  0.916256  0.762745\n",
      "1.0  0.083744  0.237255\n",
      "\n",
      " IIMEDICR\n",
      "      Overall  Criminal\n",
      "1.0  0.995673  0.986928\n",
      "3.0  0.004327  0.013072\n",
      "\n",
      " IRCHMPUS\n",
      "      Overall  Criminal\n",
      "2.0  0.962025  0.971895\n",
      "1.0  0.037975  0.028105\n",
      "\n",
      " IICHMPUS\n",
      "      Overall  Criminal\n",
      "1.0  0.997748  0.990523\n",
      "3.0  0.002252  0.009477\n",
      "\n",
      " IRPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.611044  0.977778\n",
      "2.0  0.388956  0.022222\n",
      "\n",
      " IIPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.993575  0.962418\n",
      "3.0  0.006425  0.037582\n",
      "\n",
      " IROTHHLT\n",
      "       Overall  Criminal\n",
      "99.0  0.863489  0.994444\n",
      "2.0   0.104564  0.004575\n",
      "1.0   0.031948  0.000980\n",
      "\n",
      " IIOTHHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.133354       NaN\n",
      "3.0  0.008677   0.02549\n",
      "9.0  0.857969   0.97451\n",
      "\n",
      " HLCALLFG\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " HLCALL99\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " ANYHLTI2\n",
      "       Overall  Criminal\n",
      "1.0   0.889144  0.974510\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.007043  0.021569\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.000486  0.000654\n",
      "\n",
      " IRINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.895436  0.995425\n",
      "2.0  0.104564  0.004575\n",
      "\n",
      " IIINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.991323   0.97451\n",
      "3.0  0.008677   0.02549\n",
      "\n",
      " OTHINS\n",
      "     Overall  Criminal\n",
      "2.0   0.8549  0.749673\n",
      "1.0   0.1451  0.250327\n",
      "\n",
      " CELLNOTCL\n",
      "       Overall  Criminal\n",
      "1.0   0.433312  0.477451\n",
      "2.0   0.565385  0.520588\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000442  0.000327\n",
      "97.0  0.000640  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " CELLWRKNG\n",
      "       Overall  Criminal\n",
      "1.0   0.977016  0.952614\n",
      "2.0   0.022255  0.045425\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000110  0.000327\n",
      "97.0  0.000397  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " IRFAMSOC\n",
      "      Overall  Criminal\n",
      "2.0  0.836796  0.677778\n",
      "1.0  0.163204  0.322222\n",
      "\n",
      " IIFAMSOC\n",
      "      Overall  Criminal\n",
      "1.0  0.991213  0.982026\n",
      "3.0  0.008787  0.017974\n",
      "\n",
      " IRFAMSSI\n",
      "      Overall  Criminal\n",
      "2.0  0.931446  0.926471\n",
      "1.0  0.068554  0.073529\n",
      "\n",
      " IIFAMSSI\n",
      "      Overall  Criminal\n",
      "1.0  0.991058  0.977778\n",
      "3.0  0.008942  0.022222\n",
      "\n",
      " IRFSTAMP\n",
      "      Overall  Criminal\n",
      "2.0  0.798931  0.807516\n",
      "1.0  0.201069  0.192484\n",
      "\n",
      " IIFSTAMP\n",
      "      Overall  Criminal\n",
      "1.0  0.995584  0.989869\n",
      "3.0  0.004416  0.010131\n",
      "\n",
      " IRFAMPMT\n",
      "      Overall  Criminal\n",
      "2.0  0.973197  0.975163\n",
      "1.0  0.026803  0.024837\n",
      "\n",
      " IIFAMPMT\n",
      "      Overall  Criminal\n",
      "1.0  0.993134   0.98268\n",
      "3.0  0.006866   0.01732\n",
      "\n",
      " IRFAMSVC\n",
      "      Overall  Criminal\n",
      "2.0  0.963858  0.962418\n",
      "1.0  0.036142  0.037582\n",
      "\n",
      " IIFAMSVC\n",
      "      Overall  Criminal\n",
      "1.0  0.994922  0.985621\n",
      "3.0  0.005078  0.014379\n",
      "\n",
      " IIWELMOS\n",
      "      Overall  Criminal\n",
      "9.0  0.938379  0.927124\n",
      "1.0  0.052149  0.050000\n",
      "3.0  0.009472  0.022876\n",
      "\n",
      " IRPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.468549  0.632026\n",
      "2.0  0.157132  0.181046\n",
      "3.0  0.099773  0.102941\n",
      "4.0  0.072506  0.053922\n",
      "5.0  0.058817  0.030065\n",
      "6.0  0.073102       NaN\n",
      "7.0  0.070121       NaN\n",
      "\n",
      " IRFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.082551  0.128431\n",
      "2.0  0.122248  0.166013\n",
      "3.0  0.110790  0.211765\n",
      "4.0  0.105248  0.240523\n",
      "5.0  0.099508  0.253268\n",
      "6.0  0.157022       NaN\n",
      "7.0  0.322633       NaN\n",
      "\n",
      " IIPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.969907  0.950654\n",
      "3.0  0.030093  0.049346\n",
      "\n",
      " IIFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.903385  0.860458\n",
      "3.0  0.096615  0.139542\n",
      "\n",
      " GOVTPROG\n",
      "      Overall  Criminal\n",
      "2.0  0.761332  0.757843\n",
      "1.0  0.238668  0.242157\n",
      "\n",
      " POVERTY3\n",
      "      Overall  Criminal\n",
      "1.0  0.205551   0.27451\n",
      "2.0  0.225289   0.47451\n",
      "3.0  0.569161   0.25098\n",
      "\n",
      " TOOLONG\n",
      "       Overall  Criminal\n",
      "2.0   0.924779  0.899673\n",
      "1.0   0.072594  0.097059\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " TROUBUND\n",
      "       Overall  Criminal\n",
      "2.0   0.940388  0.917320\n",
      "1.0   0.056985  0.079412\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " PDEN10\n",
      "      Overall  Criminal\n",
      "2.0  0.490584  0.538889\n",
      "1.0  0.432142  0.369608\n",
      "3.0  0.077275  0.091503\n",
      "\n",
      " COUTYP2\n",
      "      Overall  Criminal\n",
      "1.0  0.443976  0.383987\n",
      "2.0  0.348509  0.375817\n",
      "3.0  0.207516  0.240196\n",
      "\n",
      " MAIIN102\n",
      "      Overall  Criminal\n",
      "2.0  0.978915  0.979739\n",
      "1.0  0.021085  0.020261\n",
      "\n",
      " AIIND102\n",
      "      Overall  Criminal\n",
      "2.0  0.978716  0.979085\n",
      "1.0  0.021284  0.020915\n",
      "\n",
      " VEREP\n",
      "      Overall  Criminal\n",
      "1.0  0.506414  0.519608\n",
      "2.0  0.493586  0.480392\n",
      "\n",
      " Criminal\n",
      "   Overall  Criminal\n",
      "0  0.93244       NaN\n",
      "1  0.06756       1.0\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "overall = train.shape[0]\n",
    "train_criminal = train[train['Criminal']==1]\n",
    "criminal = train_criminal.shape[0]\n",
    "for col in cols:\n",
    "    if len(train[col].unique()) > 10:\n",
    "        continue\n",
    "    print('\\n', col)\n",
    "    temp = DataFrame({'Overall': train[col].value_counts() / overall,\n",
    "                      'Criminal': train_criminal[col].value_counts() / criminal})\n",
    "    print(temp[['Overall', 'Criminal']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating \"NC17\" column by removing (NRCH17_2, IRHHSIZ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NC17'] = train['NRCH17_2'] / train['IRHHSIZ2']\n",
    "del train['NRCH17_2']\n",
    "del train['IRHHSIZ2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining \"HLNV\" columns   and   \"HLCALL\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n"
     ]
    }
   ],
   "source": [
    "hlnv_cols = [col for col in train.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "train['HLNV'] = train[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in train.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "train['HLCALL'] = train[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlcall_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming \"HLCNOTMO\"  and  \"HLCLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['HLCNOTMO'] = train['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "train['HLCLAST'] = train['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 5 59\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and Frequency based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n"
     ]
    }
   ],
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "freqs = {}\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    # Get counts, sums and frequency of is_attributed\n",
    "    df = DataFrame({\n",
    "        'sums': train.groupby(col)['Criminal'].sum(),\n",
    "        'counts': train.groupby(col)['Criminal'].count()\n",
    "    })\n",
    "    df.loc[:, 'freq'] = df.sums / df.counts\n",
    "    \n",
    "    # If we have less than 3 observations, e.g. for an IP, then assume freq of 0\n",
    "    df.loc[df.counts <= 3, 'freq'] = 0      \n",
    "    \n",
    "    # Saving in dictionary\n",
    "    freqs[col] = df\n",
    "    \n",
    "    # Add to X_total\n",
    "    train[col+'_freq'] = train[col].map(df['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    #train[col] = train[col].astype('category',copy=False)\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>NC17</th>\n",
       "      <th>IFATHER_freq</th>\n",
       "      <th>IFATHER_1</th>\n",
       "      <th>IFATHER_2</th>\n",
       "      <th>IFATHER_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HLNV_15</th>\n",
       "      <th>HLNV_20</th>\n",
       "      <th>HLNV_25</th>\n",
       "      <th>HLNV_470</th>\n",
       "      <th>HLNV_485</th>\n",
       "      <th>HLNV_490</th>\n",
       "      <th>HLNV_495</th>\n",
       "      <th>HLCALL_freq</th>\n",
       "      <th>HLCALL_2</th>\n",
       "      <th>HLCALL_196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IRKI17_2  IRHH65_2  IRWELMOS     ANALWT_C  Criminal      NC17  \\\n",
       "0       3.0       1.0      99.0  3884.805998         0  0.500000   \n",
       "1       2.0       1.0      99.0  1627.108106         1  0.333333   \n",
       "\n",
       "   IFATHER_freq  IFATHER_1  IFATHER_2  IFATHER_3     ...      HLNV_15  \\\n",
       "0      0.058072          0          0          0     ...            0   \n",
       "1      0.058072          0          0          0     ...            0   \n",
       "\n",
       "   HLNV_20  HLNV_25  HLNV_470  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  \\\n",
       "0        0        0         0         0         0         1     0.067419   \n",
       "1        0        0         0         0         0         1     0.067419   \n",
       "\n",
       "   HLCALL_2  HLCALL_196  \n",
       "0         0           1  \n",
       "1         0           1  \n",
       "\n",
       "[2 rows x 314 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X['download_time'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing Multicollinearity (using VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "from numpy import arange, delete\n",
    "\n",
    "def calculate_vif(X, thresh=100):\n",
    "    cols = X.columns\n",
    "    variables = arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = calculate_vif(X, 10)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45247, 313) (46, 313)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.001, random_state=15)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(X_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAImCAYAAAAG8zQtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDh06TBn+P9L9fYCVjcBEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fa9492ab00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp[:30].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(15,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IRFAMIN3_freq', 'ANALWT_C', 'VESTR_freq', 'POVERTY3_freq', 'IRPINC3_freq', 'POVERTY3_3', 'IRPINC3_1', 'IRFAMIN3_7', 'GRPHLTIN_freq', 'IFATHER_freq', 'IRFAMIN3_6', 'IRFAMIN3_5', 'IFATHER_4', 'IRKI17_2', 'POVERTY3_2', 'PRVHLTIN_2', 'IRFAMIN3_4', 'GRPHLTIN_99', 'PRVHLTIN_freq', 'IRPRVHLT_freq', 'IRPRVHLT_1', 'IRPRVHLT_2', 'POVERTY3_1', 'NC17', 'COUTYP2_freq', 'PRVHLTIN_1', 'PRXYDATA_freq', 'IRFAMIN3_3', 'PRXYDATA_99', 'GRPHLTIN_1']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = list(feat_imp[:30].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[imp_feats]\n",
    "X_train = X_train[imp_feats]\n",
    "X_test = X_test[imp_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=et)\n",
    "gb = GradientBoostingClassifier()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfe = RFE(rf, step=0.2)\n",
    "select = SelectFromModel(rf)\n",
    "kbest = SelectKBest(chi2)\n",
    "\n",
    "pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "\n",
    "feat_sel_params = [\n",
    "    {\n",
    "        'feat_sel': [kbest],\n",
    "        'feat_sel__k': [20, 30]},\n",
    "    {\n",
    "        'feat_sel': [rfe],\n",
    "        'feat_sel__estimator': [gb], #rf, et, \n",
    "        'feat_sel__n_features_to_select': [20]},\n",
    "    {\n",
    "        'feat_sel': [select],\n",
    "        'feat_sel__estimator': [gb]} #rf, et, \n",
    "]\n",
    "\n",
    "model_params = [\n",
    "    {\n",
    "        'model': [lr]},\n",
    "    {\n",
    "        'model': [gb],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.5]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "    {\n",
    "        'model': [ada],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.5], #0.01, 0.04, 0.1, 0.5, 1\n",
    "        'model__random_state': [2]},\n",
    "    {\n",
    "        'model': [rf],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7, 9\n",
    "        'model__max_depth': [9]}, #8, 10, 14\n",
    "    {\n",
    "        'model': [et],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7\n",
    "        'model__max_depth': [9]} #8, 10, 14\n",
    "]\n",
    "\n",
    "params = []\n",
    "for feat_sel in feat_sel_params:\n",
    "    for model in model_params:\n",
    "        # Merge dictionaries and append to list\n",
    "        params.append({**feat_sel, **model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).sort_values('rank_test_score').to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    et = ExtraTreesClassifier(n_estimators=100)\n",
    "    xg = xgb.XGBClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100)\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    models = {\n",
    "        'rf': rf,\n",
    "        'lr': lr,\n",
    "        'xg': xg,\n",
    "        'et': et,\n",
    "        'gb': gb,\n",
    "        'ada': ada\n",
    "    }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_all(models, X_train, y_train, X_test, y_test, prob=False):\n",
    "    preds = DataFrame()\n",
    "    preds['y_true'] = y # Check for y and y_test\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        print('\\n', key)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[key] = model\n",
    "        \n",
    "        if prob:\n",
    "            pred = model.predict_proba(X) # Check for X and X_test   \n",
    "            # preds[key+'_0'] = [i[0] for i in pred]\n",
    "            preds[key+'_1'] = [i[1] for i in pred]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            preds[key] = model.predict(X) # Check for X and X_test       \n",
    "            print('MCC:', matthews_corrcoef(preds['y_true'], preds[key]))\n",
    "            print('Acc:', accuracy_score(preds['y_true'], preds[key]))\n",
    "            print('Confusion Matrix\\n', confusion_matrix(preds['y_true'], preds[key]))\n",
    "    \n",
    "    if prob:\n",
    "        preds.to_excel('ensemble_proba.xlsx', index=False)\n",
    "    else:\n",
    "        preds.to_excel('ensemble_preds.xlsx', index=False)\n",
    "    \n",
    "    return preds, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " rf\n",
      "\n",
      " lr\n",
      "\n",
      " xg\n",
      "\n",
      " et\n",
      "\n",
      " gb\n",
      "\n",
      " ada\n"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "pred_all, trained_models = predict_all(models, X_train, y_train, X_test, y_test, True) # Probability True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.710226495021\n",
      "Acc: 0.967699202967\n",
      "Confusion Matrix\n",
      " [[42233     0]\n",
      " [ 1463  1597]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nanmean\n",
    "\n",
    "pred_all['final'] = pred_all.loc[:,'rf':'ada'].apply(lambda row: round(nanmean(row.values)), axis=1)\n",
    "\n",
    "print('MCC:', matthews_corrcoef(pred_all['y_true'], pred_all['final']))\n",
    "print('Acc:', accuracy_score(pred_all['y_true'], pred_all['final']))\n",
    "print('Confusion Matrix\\n', confusion_matrix(pred_all['y_true'], pred_all['final']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>rf_1</th>\n",
       "      <th>lr_1</th>\n",
       "      <th>xg_1</th>\n",
       "      <th>et_1</th>\n",
       "      <th>gb_1</th>\n",
       "      <th>ada_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>0.033207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.303952</td>\n",
       "      <td>0.286323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.277212</td>\n",
       "      <td>0.878178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true  rf_1      lr_1      xg_1  et_1      gb_1     ada_1\n",
       "0       0  0.00  0.002740  0.000308   0.0  0.003713  0.033207\n",
       "1       1  0.68  0.303952  0.286323   1.0  0.277212  0.878178"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "pred_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metalearner on Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       IRFAMIN3_freq     ANALWT_C  VESTR_freq  POVERTY3_freq  IRPINC3_freq  \\\n",
      "38999            0.0  1113.110137    0.067265       0.029792      0.000000   \n",
      "33203            0.0  1503.750666    0.063830       0.029792      0.034535   \n",
      "\n",
      "       POVERTY3_3  IRPINC3_1  IRFAMIN3_7  GRPHLTIN_freq  IFATHER_freq  \\\n",
      "38999           1          0           1       0.092235      0.058072   \n",
      "33203           1          0           1       0.092235      0.058072   \n",
      "\n",
      "          ...      IRPRVHLT_1  IRPRVHLT_2  POVERTY3_1      NC17  COUTYP2_freq  \\\n",
      "38999     ...               1           0           0  0.333333      0.058432   \n",
      "33203     ...               1           0           0  0.000000      0.058432   \n",
      "\n",
      "       PRVHLTIN_1  PRXYDATA_freq  IRFAMIN3_3  PRXYDATA_99  GRPHLTIN_1  \n",
      "38999           1       0.060433           0            1           1  \n",
      "33203           1       0.060433           0            1           1  \n",
      "\n",
      "[2 rows x 30 columns]\n",
      "\n",
      " (45247, 6) (46, 6)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y = pred_all['y_true']\n",
    "X = pred_all.drop('y_true', axis=1)\n",
    "print(X_train.head(2))\n",
    "\n",
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.001, random_state=10)\n",
    "print('\\n', X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_model = GradientBoostingClassifier(n_estimators=1000)\n",
    "meta_pred = meta_model.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n",
      "Acc: 1.0\n",
      "Confusion Matrix\n",
      " [[43  0]\n",
      " [ 0  3]]\n"
     ]
    }
   ],
   "source": [
    "print('MCC:', matthews_corrcoef(y_test, meta_pred))\n",
    "print('Acc:', accuracy_score(y_test, meta_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, meta_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier((100, 25), max_iter=200,tol=0, verbose=10)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = nn\n",
    "y_pred = best_model.predict(X_test)\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.03],   # Learning rate alpha\n",
    "    'max_depth': [10],   # maximum depth of the tree\n",
    "    'gamma': [0.1, 0.5],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [3, 6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [100],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=50, scoring=make_scorer(matthews_corrcoef), n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imp_feats = X_train.columns.values[grid.best_params_.get_support(indices=True)]\n",
    "# print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "xgb_model = grid.best_estimator_.fit(X_train, y_train) #[imp_feats]\n",
    "y_pred = xgb_model.predict(X_test) #[imp_feats]\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    #'num_class': 2     # num_class not required with the Binary Logistic\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "from numpy import linspace, array\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    thresholds = linspace(0.01, 0.99, 50)\n",
    "    mcc = array([matthews_corrcoef(labels, preds>thr) for thr in thresholds])\n",
    "    best_score = mcc.max()\n",
    "    return 'mcc', -best_score\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, feval = evalerror, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  66583679        4       0.0         4         1         2         1   \n",
      "1  35494679        4       0.0         4         1         1         1   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY  ...    POVERTY3  TOOLONG  TROUBUND  PDEN10  \\\n",
      "0         1         1        99  ...         2.0        2         2       1   \n",
      "1         1         1        99  ...         3.0        2         2       1   \n",
      "\n",
      "   COUTYP2  MAIIN102  AIIND102      ANALWT_C  VESTR  VEREP  \n",
      "0        1         2         2  16346.795400  40020      1  \n",
      "1        1         2         2   3008.863906  40044      2  \n",
      "\n",
      "[2 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv', na_values=-1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n",
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n",
      "   IRKI17_2  IRHH65_2  IRWELMOS      ANALWT_C  NC17  IFATHER_freq  IFATHER_1  \\\n",
      "0         2         1        99  16346.795400   0.0      0.058072          0   \n",
      "1         1         1        99   3008.863906   0.0      0.058072          0   \n",
      "\n",
      "   IFATHER_2  IFATHER_3  IFATHER_4     ...      HLNV_freq  HLNV_15  HLNV_20  \\\n",
      "0          0          0          1     ...       0.067787        0        0   \n",
      "1          0          0          1     ...       0.067787        0        0   \n",
      "\n",
      "   HLNV_25  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  HLCALL_2  HLCALL_196  \n",
      "0        0         0         0         1     0.067419         0           1  \n",
      "1        0         0         0         1     0.067419         0           1  \n",
      "\n",
      "[2 rows x 317 columns]\n"
     ]
    }
   ],
   "source": [
    "perid = test['PERID']\n",
    "test.drop('PERID', axis=1, inplace=True)\n",
    "\n",
    "from numpy import inf, nan\n",
    "test = test.replace([inf, -inf, nan], 0).fillna(0)\n",
    "\n",
    "test['NC17'] = test['NRCH17_2'] / test['IRHHSIZ2']\n",
    "del test['NRCH17_2']\n",
    "del test['IRHHSIZ2']\n",
    "\n",
    "hlnv_cols = [col for col in test.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "test['HLNV'] = test[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in test.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "test['HLCALL'] = test[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlcall_cols, axis=1)\n",
    "\n",
    "test['HLCNOTMO'] = test['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "test['HLCLAST'] = test['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)\n",
    "\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in test.columns.values if col not in num_cols]\n",
    "\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    test[col+'_freq'] = test[col].map(freqs[col]['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    test[col] = test[col].astype('category',copy=False)\n",
    "    temp = get_dummies(test[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    test = test.join(temp)\n",
    "    test = test.drop(col,axis=1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level-1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna(0)\n",
    "meta_test = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, model in trained_models.items():\n",
    "    meta_test[key] = model.predict(test[imp_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rf  lr  xg  et  gb  ada  Criminal     PERID\n",
      "0   0   0   0   0   0    0         0  66583679\n",
      "1   0   0   0   0   0    0         0  35494679\n"
     ]
    }
   ],
   "source": [
    "meta_test['Criminal'] = meta_model.predict(meta_test)\n",
    "meta_test['PERID'] = perid\n",
    "print(meta_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_test[['PERID', 'Criminal']].to_csv('final_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criminal  number: 681, percent: 0.05958005249343832\n"
     ]
    }
   ],
   "source": [
    "nc = sum(meta_test['Criminal'])\n",
    "print('Criminal  number: {}, percent: {}'.format(nc, nc / meta_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
