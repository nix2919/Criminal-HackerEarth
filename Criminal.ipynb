{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA',\n",
       "       'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN',\n",
       "       'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN',\n",
       "       'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR',\n",
       "       'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS',\n",
       "       'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4',\n",
       "       'OTHINS', 'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC',\n",
       "       'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT',\n",
       "       'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS',\n",
       "       'IRPINC3', 'IRFAMIN3', 'IIPINC3', 'IIFAMIN3', 'GOVTPROG',\n",
       "       'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP2', 'MAIIN102',\n",
       "       'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP', 'Criminal'], dtype=object)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "from numpy import inf, nan\n",
    "train = train.replace([inf, -inf], nan).dropna()\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "\n",
      " IFATHER\n",
      "      Overall  Criminal\n",
      "4.0  0.760758  0.653922\n",
      "1.0  0.171726  0.200000\n",
      "2.0  0.067339  0.145425\n",
      "3.0  0.000177  0.000654\n",
      "\n",
      " NRCH17_2\n",
      "      Overall  Criminal\n",
      "0.0  0.731548  0.889869\n",
      "1.0  0.110370  0.051634\n",
      "2.0  0.101804  0.037582\n",
      "3.0  0.056278  0.020915\n",
      "\n",
      " IRHHSIZ2\n",
      "      Overall  Criminal\n",
      "1.0  0.078489  0.139869\n",
      "2.0  0.222639  0.267974\n",
      "3.0  0.223147  0.217320\n",
      "4.0  0.239309  0.191503\n",
      "5.0  0.136003  0.101634\n",
      "6.0  0.100413  0.081699\n",
      "\n",
      " IIHHSIZ2\n",
      "     Overall  Criminal\n",
      "1.0      1.0       1.0\n",
      "\n",
      " IRKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.417084  0.494771\n",
      "2.0  0.223015  0.191176\n",
      "3.0  0.210695  0.176797\n",
      "4.0  0.149206  0.137255\n",
      "\n",
      " IIKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.997726  0.997712\n",
      "3.0  0.002274  0.002288\n",
      "\n",
      " IRHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.878193  0.741503\n",
      "2.0  0.079725  0.149346\n",
      "3.0  0.042082  0.109150\n",
      "\n",
      " IIHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.995474  0.995425\n",
      "3.0  0.004018  0.004248\n",
      "2.0  0.000508  0.000327\n",
      "\n",
      " PRXRETRY\n",
      "       Overall  Criminal\n",
      "2.0   0.016603  0.014706\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000110       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.982359  0.983987\n",
      "\n",
      " PRXYDATA\n",
      "       Overall  Criminal\n",
      "1.0   0.288676  0.363399\n",
      "2.0   0.000839  0.000654\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000066       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.709492  0.634641\n",
      "\n",
      " MEDICARE\n",
      "       Overall  Criminal\n",
      "2.0   0.912106  0.750327\n",
      "1.0   0.083567  0.236601\n",
      "94.0  0.003466  0.010131\n",
      "97.0  0.000773  0.002288\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " CAIDCHIP\n",
      "       Overall  Criminal\n",
      "1.0   0.225377  0.092484\n",
      "2.0   0.765659  0.882353\n",
      "85.0  0.001126  0.001307\n",
      "94.0  0.006911  0.020588\n",
      "97.0  0.000927  0.003268\n",
      "\n",
      " CHAMPUS\n",
      "       Overall  Criminal\n",
      "2.0   0.959817  0.962418\n",
      "1.0   0.037931  0.028105\n",
      "94.0  0.001590  0.006863\n",
      "97.0  0.000574  0.001961\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " PRVHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.607644  0.962418\n",
      "2.0   0.385932       NaN\n",
      "85.0  0.000088  0.000654\n",
      "94.0  0.005431  0.033007\n",
      "97.0  0.000905  0.003922\n",
      "\n",
      " GRPHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.535712  0.731373\n",
      "2.0   0.070386  0.224183\n",
      "85.0  0.000066  0.000327\n",
      "94.0  0.001523  0.006536\n",
      "97.0  0.000927  0.004248\n",
      "98.0  0.005453  0.033333\n",
      "99.0  0.385932       NaN\n",
      "\n",
      " HLTINNOS\n",
      "       Overall  Criminal\n",
      "1.0   0.031175       NaN\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.000486       NaN\n",
      "97.0  0.000132       NaN\n",
      "99.0  0.866028       1.0\n",
      "\n",
      " HLCNOTYR\n",
      "       Overall  Criminal\n",
      "1.0   0.071777  0.054575\n",
      "2.0   0.815402  0.914706\n",
      "85.0  0.000464  0.000654\n",
      "94.0  0.001943  0.004902\n",
      "97.0  0.001170  0.003595\n",
      "98.0  0.007065  0.021569\n",
      "99.0  0.102179       NaN\n",
      "\n",
      " HLCLAST\n",
      "       Overall  Criminal\n",
      "1.0   0.019208       NaN\n",
      "2.0   0.012320       NaN\n",
      "3.0   0.021063       NaN\n",
      "4.0   0.028967       NaN\n",
      "5.0   0.019849       NaN\n",
      "94.0  0.000729       NaN\n",
      "97.0  0.001192  0.003268\n",
      "98.0  0.007529  0.022222\n",
      "99.0  0.889144  0.974510\n",
      "\n",
      " HLNVCOST\n",
      "       Overall  Criminal\n",
      "1.0   0.009913       NaN\n",
      "6.0   0.009869       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVOFFR\n",
      "       Overall  Criminal\n",
      "1.0   0.002914       NaN\n",
      "6.0   0.016868       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVREF\n",
      "       Overall  Criminal\n",
      "1.0   0.000596       NaN\n",
      "6.0   0.019186       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVNEED\n",
      "       Overall  Criminal\n",
      "1.0   0.003974       NaN\n",
      "6.0   0.015808       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVSOR\n",
      "       Overall  Criminal\n",
      "1.0   0.002936       NaN\n",
      "6.0   0.016846       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " IRMCDCHP\n",
      "     Overall  Criminal\n",
      "2.0  0.77151  0.895425\n",
      "1.0  0.22849  0.104575\n",
      "\n",
      " IIMCDCHP\n",
      "      Overall  Criminal\n",
      "1.0  0.991036  0.974837\n",
      "3.0  0.008964  0.025163\n",
      "\n",
      " IRMEDICR\n",
      "      Overall  Criminal\n",
      "2.0  0.916256  0.762745\n",
      "1.0  0.083744  0.237255\n",
      "\n",
      " IIMEDICR\n",
      "      Overall  Criminal\n",
      "1.0  0.995673  0.986928\n",
      "3.0  0.004327  0.013072\n",
      "\n",
      " IRCHMPUS\n",
      "      Overall  Criminal\n",
      "2.0  0.962025  0.971895\n",
      "1.0  0.037975  0.028105\n",
      "\n",
      " IICHMPUS\n",
      "      Overall  Criminal\n",
      "1.0  0.997748  0.990523\n",
      "3.0  0.002252  0.009477\n",
      "\n",
      " IRPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.611044  0.977778\n",
      "2.0  0.388956  0.022222\n",
      "\n",
      " IIPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.993575  0.962418\n",
      "3.0  0.006425  0.037582\n",
      "\n",
      " IROTHHLT\n",
      "       Overall  Criminal\n",
      "99.0  0.863489  0.994444\n",
      "2.0   0.104564  0.004575\n",
      "1.0   0.031948  0.000980\n",
      "\n",
      " IIOTHHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.133354       NaN\n",
      "3.0  0.008677   0.02549\n",
      "9.0  0.857969   0.97451\n",
      "\n",
      " HLCALLFG\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " HLCALL99\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " ANYHLTI2\n",
      "       Overall  Criminal\n",
      "1.0   0.889144  0.974510\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.007043  0.021569\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.000486  0.000654\n",
      "\n",
      " IRINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.895436  0.995425\n",
      "2.0  0.104564  0.004575\n",
      "\n",
      " IIINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.991323   0.97451\n",
      "3.0  0.008677   0.02549\n",
      "\n",
      " OTHINS\n",
      "     Overall  Criminal\n",
      "2.0   0.8549  0.749673\n",
      "1.0   0.1451  0.250327\n",
      "\n",
      " CELLNOTCL\n",
      "       Overall  Criminal\n",
      "1.0   0.433312  0.477451\n",
      "2.0   0.565385  0.520588\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000442  0.000327\n",
      "97.0  0.000640  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " CELLWRKNG\n",
      "       Overall  Criminal\n",
      "1.0   0.977016  0.952614\n",
      "2.0   0.022255  0.045425\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000110  0.000327\n",
      "97.0  0.000397  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " IRFAMSOC\n",
      "      Overall  Criminal\n",
      "2.0  0.836796  0.677778\n",
      "1.0  0.163204  0.322222\n",
      "\n",
      " IIFAMSOC\n",
      "      Overall  Criminal\n",
      "1.0  0.991213  0.982026\n",
      "3.0  0.008787  0.017974\n",
      "\n",
      " IRFAMSSI\n",
      "      Overall  Criminal\n",
      "2.0  0.931446  0.926471\n",
      "1.0  0.068554  0.073529\n",
      "\n",
      " IIFAMSSI\n",
      "      Overall  Criminal\n",
      "1.0  0.991058  0.977778\n",
      "3.0  0.008942  0.022222\n",
      "\n",
      " IRFSTAMP\n",
      "      Overall  Criminal\n",
      "2.0  0.798931  0.807516\n",
      "1.0  0.201069  0.192484\n",
      "\n",
      " IIFSTAMP\n",
      "      Overall  Criminal\n",
      "1.0  0.995584  0.989869\n",
      "3.0  0.004416  0.010131\n",
      "\n",
      " IRFAMPMT\n",
      "      Overall  Criminal\n",
      "2.0  0.973197  0.975163\n",
      "1.0  0.026803  0.024837\n",
      "\n",
      " IIFAMPMT\n",
      "      Overall  Criminal\n",
      "1.0  0.993134   0.98268\n",
      "3.0  0.006866   0.01732\n",
      "\n",
      " IRFAMSVC\n",
      "      Overall  Criminal\n",
      "2.0  0.963858  0.962418\n",
      "1.0  0.036142  0.037582\n",
      "\n",
      " IIFAMSVC\n",
      "      Overall  Criminal\n",
      "1.0  0.994922  0.985621\n",
      "3.0  0.005078  0.014379\n",
      "\n",
      " IIWELMOS\n",
      "      Overall  Criminal\n",
      "9.0  0.938379  0.927124\n",
      "1.0  0.052149  0.050000\n",
      "3.0  0.009472  0.022876\n",
      "\n",
      " IRPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.468549  0.632026\n",
      "2.0  0.157132  0.181046\n",
      "3.0  0.099773  0.102941\n",
      "4.0  0.072506  0.053922\n",
      "5.0  0.058817  0.030065\n",
      "6.0  0.073102       NaN\n",
      "7.0  0.070121       NaN\n",
      "\n",
      " IRFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.082551  0.128431\n",
      "2.0  0.122248  0.166013\n",
      "3.0  0.110790  0.211765\n",
      "4.0  0.105248  0.240523\n",
      "5.0  0.099508  0.253268\n",
      "6.0  0.157022       NaN\n",
      "7.0  0.322633       NaN\n",
      "\n",
      " IIPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.969907  0.950654\n",
      "3.0  0.030093  0.049346\n",
      "\n",
      " IIFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.903385  0.860458\n",
      "3.0  0.096615  0.139542\n",
      "\n",
      " GOVTPROG\n",
      "      Overall  Criminal\n",
      "2.0  0.761332  0.757843\n",
      "1.0  0.238668  0.242157\n",
      "\n",
      " POVERTY3\n",
      "      Overall  Criminal\n",
      "1.0  0.205551   0.27451\n",
      "2.0  0.225289   0.47451\n",
      "3.0  0.569161   0.25098\n",
      "\n",
      " TOOLONG\n",
      "       Overall  Criminal\n",
      "2.0   0.924779  0.899673\n",
      "1.0   0.072594  0.097059\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " TROUBUND\n",
      "       Overall  Criminal\n",
      "2.0   0.940388  0.917320\n",
      "1.0   0.056985  0.079412\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " PDEN10\n",
      "      Overall  Criminal\n",
      "2.0  0.490584  0.538889\n",
      "1.0  0.432142  0.369608\n",
      "3.0  0.077275  0.091503\n",
      "\n",
      " COUTYP2\n",
      "      Overall  Criminal\n",
      "1.0  0.443976  0.383987\n",
      "2.0  0.348509  0.375817\n",
      "3.0  0.207516  0.240196\n",
      "\n",
      " MAIIN102\n",
      "      Overall  Criminal\n",
      "2.0  0.978915  0.979739\n",
      "1.0  0.021085  0.020261\n",
      "\n",
      " AIIND102\n",
      "      Overall  Criminal\n",
      "2.0  0.978716  0.979085\n",
      "1.0  0.021284  0.020915\n",
      "\n",
      " VEREP\n",
      "      Overall  Criminal\n",
      "1.0  0.506414  0.519608\n",
      "2.0  0.493586  0.480392\n",
      "\n",
      " Criminal\n",
      "   Overall  Criminal\n",
      "0  0.93244       NaN\n",
      "1  0.06756       1.0\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "overall = train.shape[0]\n",
    "train_criminal = train[train['Criminal']==1]\n",
    "criminal = train_criminal.shape[0]\n",
    "for col in cols:\n",
    "    if len(train[col].unique()) > 10:\n",
    "        continue\n",
    "    print('\\n', col)\n",
    "    temp = DataFrame({'Overall': train[col].value_counts() / overall,\n",
    "                      'Criminal': train_criminal[col].value_counts() / criminal})\n",
    "    print(temp[['Overall', 'Criminal']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating \"NC17\" column by removing (NRCH17_2, IRHHSIZ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['NC17'] = train['NRCH17_2'] / train['IRHHSIZ2']\n",
    "del train['NRCH17_2']\n",
    "del train['IRHHSIZ2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining \"HLNV\" columns   and   \"HLCALL\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n"
     ]
    }
   ],
   "source": [
    "hlnv_cols = [col for col in train.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "train['HLNV'] = train[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in train.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "train['HLCALL'] = train[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlcall_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming \"HLCNOTMO\"  and  \"HLCLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['HLCNOTMO'] = train['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "train['HLCLAST'] = train['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 5 59\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and Frequency based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n"
     ]
    }
   ],
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "freqs = {}\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    # Get counts, sums and frequency of is_attributed\n",
    "    df = DataFrame({\n",
    "        'sums': train.groupby(col)['Criminal'].sum(),\n",
    "        'counts': train.groupby(col)['Criminal'].count()\n",
    "    })\n",
    "    df.loc[:, 'freq'] = df.sums / df.counts\n",
    "    \n",
    "    # If we have less than 3 observations, e.g. for an IP, then assume freq of 0\n",
    "    df.loc[df.counts <= 3, 'freq'] = 0      \n",
    "    \n",
    "    # Saving in dictionary\n",
    "    freqs[col] = df\n",
    "    \n",
    "    # Add to X_total\n",
    "    train[col+'_freq'] = train[col].map(df['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    #train[col] = train[col].astype('category',copy=False)\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>NC17</th>\n",
       "      <th>IFATHER_freq</th>\n",
       "      <th>IFATHER_1</th>\n",
       "      <th>IFATHER_2</th>\n",
       "      <th>IFATHER_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HLNV_15</th>\n",
       "      <th>HLNV_20</th>\n",
       "      <th>HLNV_25</th>\n",
       "      <th>HLNV_470</th>\n",
       "      <th>HLNV_485</th>\n",
       "      <th>HLNV_490</th>\n",
       "      <th>HLNV_495</th>\n",
       "      <th>HLCALL_freq</th>\n",
       "      <th>HLCALL_2</th>\n",
       "      <th>HLCALL_196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IRKI17_2  IRHH65_2  IRWELMOS     ANALWT_C  Criminal      NC17  \\\n",
       "0       3.0       1.0      99.0  3884.805998         0  0.500000   \n",
       "1       2.0       1.0      99.0  1627.108106         1  0.333333   \n",
       "\n",
       "   IFATHER_freq  IFATHER_1  IFATHER_2  IFATHER_3     ...      HLNV_15  \\\n",
       "0      0.058072          0          0          0     ...            0   \n",
       "1      0.058072          0          0          0     ...            0   \n",
       "\n",
       "   HLNV_20  HLNV_25  HLNV_470  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  \\\n",
       "0        0        0         0         0         0         1     0.067419   \n",
       "1        0        0         0         0         0         1     0.067419   \n",
       "\n",
       "   HLCALL_2  HLCALL_196  \n",
       "0         0           1  \n",
       "1         0           1  \n",
       "\n",
       "[2 rows x 314 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X['download_time'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing Multicollinearity (using VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "from numpy import arange, delete\n",
    "\n",
    "def calculate_vif(X, thresh=100):\n",
    "    cols = X.columns\n",
    "    variables = arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = calculate_vif(X, 10)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45247, 313) (46, 313)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.001, random_state=25)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(X_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAImCAYAAAAG8zQtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20307fe2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp[:30].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(15,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IRFAMIN3_freq', 'ANALWT_C', 'VESTR_freq', 'POVERTY3_freq', 'IRPINC3_freq', 'POVERTY3_3', 'IRFAMIN3_7', 'IRPINC3_1', 'IFATHER_freq', 'IRFAMIN3_6', 'GRPHLTIN_freq', 'IRFAMIN3_5', 'POVERTY3_2', 'IRKI17_2', 'IFATHER_4', 'GRPHLTIN_99', 'PRVHLTIN_2', 'PRVHLTIN_freq', 'IRFAMIN3_4', 'IRPRVHLT_1', 'POVERTY3_1', 'IRPRVHLT_2', 'IRPRVHLT_freq', 'NC17', 'COUTYP2_freq', 'PRXYDATA_freq', 'IRFAMIN3_3', 'GRPHLTIN_1', 'PRXYDATA_1', 'PRXYDATA_99', 'PRVHLTIN_1', 'VEREP_1', 'VEREP_2', 'VEREP_freq', 'PDEN10_freq', 'IRHH65_2', 'GRPHLTIN_2', 'COUTYP2_2', 'IFATHER_2', 'IFATHER_1', 'CELLNOTCL_1', 'CELLNOTCL_freq', 'PDEN10_2', 'CELLNOTCL_2', 'COUTYP2_3', 'IRMEDICR_freq', 'MEDICARE_2', 'IRPINC3_2', 'IRFAMIN3_2', 'IRMEDICR_2', 'COUTYP2_1', 'IRFAMSOC_1', 'IRFAMSOC_freq', 'MEDICARE_freq', 'PDEN10_1', 'IRFAMSOC_2', 'IRFAMIN3_1', 'IRPINC3_3', 'IRMEDICR_1', 'MEDICARE_1', 'TOOLONG_freq', 'GOVTPROG_1', 'IIFAMIN3_3', 'IIFAMIN3_1', 'IIFAMIN3_freq', 'IRFSTAMP_2', 'IRFSTAMP_1', 'TOOLONG_1', 'TOOLONG_2', 'VESTR_40049', 'CAIDCHIP_freq', 'OTHINS_1', 'OTHINS_2', 'GOVTPROG_2', 'GOVTPROG_freq', 'IRFSTAMP_freq', 'TROUBUND_freq', 'PDEN10_3', 'TROUBUND_2', 'TROUBUND_1', 'OTHINS_freq', 'CAIDCHIP_1', 'IRPINC3_4', 'VESTR_40023', 'VESTR_40038', 'VESTR_40043', 'VESTR_40010', 'IRMCDCHP_freq', 'VESTR_40028', 'VESTR_40029', 'VESTR_40041', 'VESTR_40021', 'VESTR_40039', 'CAIDCHIP_2', 'IRMCDCHP_2', 'HLCNOTYR_freq', 'VESTR_40048', 'VESTR_40005', 'VESTR_40018', 'VESTR_40022', 'VESTR_40045', 'VESTR_40025', 'VESTR_40040', 'VESTR_40024', 'VESTR_40046', 'VESTR_40035', 'IRMCDCHP_1', 'VESTR_40019', 'VESTR_40013', 'VESTR_40007', 'VESTR_40012', 'VESTR_40009', 'VESTR_40001', 'VESTR_40026', 'VESTR_40004', 'IRFAMSSI_freq', 'IRFAMSSI_1', 'VESTR_40020', 'IRFAMSSI_2', 'VESTR_40003', 'VESTR_40017', 'VESTR_40014', 'VESTR_40047', 'CELLWRKNG_freq', 'VESTR_40011', 'VESTR_40034', 'HLCNOTYR_2', 'VESTR_40008', 'VESTR_40033', 'VESTR_40036', 'IRWELMOS', 'VESTR_40044', 'HLCNOTYR_1', 'HLCNOTMO_0', 'VESTR_40016', 'VESTR_40027', 'HLCNOTMO_1', 'VESTR_40032', 'VESTR_40031', 'CELLWRKNG_1', 'CELLWRKNG_2', 'HLCNOTMO_freq', 'VESTR_40015', 'VESTR_40042', 'IRPINC3_5', 'VESTR_40002', 'VESTR_40006', 'IIPINC3_3', 'IIPINC3_1', 'IIPINC3_freq', 'VESTR_40050', 'VESTR_40030', 'VESTR_40037', 'IIWELMOS_freq', 'IIWELMOS_9', 'IRPINC3_6', 'IIPRVHLT_3', 'IRPINC3_7', 'IIPRVHLT_1', 'IIWELMOS_1', 'IIPRVHLT_freq', 'PRVHLTIN_94', 'GRPHLTIN_98', 'IRFAMSVC_freq', 'PRXRETRY_freq', 'IRFAMSVC_2', 'CHAMPUS_freq', 'IRFAMSVC_1', 'PRXRETRY_2', 'PRXRETRY_99', 'HLTINNOS_99', 'CHAMPUS_2', 'IRFAMPMT_freq', 'IRFAMPMT_2', 'IRCHMPUS_1', 'CHAMPUS_1', 'IRCHMPUS_freq', 'IRFAMPMT_1', 'IRCHMPUS_2', 'IROTHHLT_99', 'AIIND102_2', 'MAIIN102_freq', 'AIIND102_freq', 'AIIND102_1', 'MAIIN102_1', 'GRPHLTIN_94', 'MAIIN102_2', 'IIFAMSSI_freq', 'IIOTHHLT_freq', 'IIFAMSSI_3', 'IIFAMSSI_1', 'ANYHLTI2_freq', 'IIWELMOS_3', 'IIFAMSOC_3', 'IIFAMSOC_1', 'HLTINNOS_freq', 'IIFAMSOC_freq', 'IIMCDCHP_freq', 'IIMCDCHP_1', 'CAIDCHIP_94', 'IROTHHLT_freq', 'IIOTHHLT_9', 'IIMCDCHP_3', 'IIOTHHLT_1', 'IIFAMPMT_freq', 'IIFAMPMT_3', 'IIFAMPMT_1', 'IIHH65_2_freq', 'IIHH65_2_1', 'IRINSUR4_2', 'HLLOSRSN_freq', 'HLCLAST_0', 'IIHH65_2_3', 'IIKI17_2_3', 'IROTHHLT_2', 'IIFAMSVC_3', 'IIFAMSVC_1', 'IIKI17_2_freq', 'IIFAMSVC_freq', 'IIKI17_2_1', 'IIFSTAMP_1', 'HLNV_freq', 'IIFSTAMP_freq', 'IIFSTAMP_3', 'HLCLAST_1', 'TOOLONG_98', 'ANYHLTI2_1', 'HLCNOTYR_99', 'HLCNOTYR_94', 'HLLOSRSN_99', 'IIINSUR4_1', 'TROUBUND_98', 'HLTINNOS_2', 'MEDICARE_94', 'IIMEDICR_3', 'ANYHLTI2_94', 'IIINSUR4_3', 'IRINSUR4_1', 'IIMEDICR_freq', 'IICHMPUS_freq', 'IIMEDICR_1', 'IIINSUR4_freq', 'HLNV_495', 'HLNV_490', 'HLCNOTYR_98', 'IICHMPUS_1', 'IICHMPUS_3', 'ANYHLTI2_2', 'IIOTHHLT_3', 'CHAMPUS_94', 'HLLOSRSN_98', 'CELLWRKNG_94', 'IRINSUR4_freq', 'GRPHLTIN_97', 'HLCLAST_freq', 'HLCALL_196', 'HLCALL_2', 'IROTHHLT_1', 'HLCALL_freq', 'IIHH65_2_2', 'CELLNOTCL_94', 'PRVHLTIN_97', 'PRXYDATA_94', 'PRXRETRY_94', 'CAIDCHIP_97', 'PRXYDATA_2', 'IFATHER_3', 'CELLNOTCL_97', 'CAIDCHIP_85', 'CHAMPUS_97', 'HLLOSRSN_97', 'HLNV_485', 'ANYHLTI2_97', 'HLTINNOS_1', 'HLCNOTYR_97', 'CELLWRKNG_97', 'MEDICARE_97', 'CHAMPUS_85', 'GRPHLTIN_85', 'PRXRETRY_98']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = list(feat_imp[:280].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[imp_feats]\n",
    "X_train = X_train[imp_feats]\n",
    "X_test = X_test[imp_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline_params():\n",
    "    rf = RandomForestClassifier()\n",
    "    et = ExtraTreesClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    xg = xgb.XGBClassifier()\n",
    "    gb = GradientBoostingClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    rfe = RFE(rf, step=0.2)\n",
    "    select = SelectFromModel(rf)\n",
    "    kbest = SelectKBest(chi2)\n",
    "    pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "    feat_sel_params = [\n",
    "        {\n",
    "            'feat_sel': [kbest],\n",
    "            'feat_sel__k': [30]},\n",
    "        {\n",
    "            'feat_sel': [rfe],\n",
    "            'feat_sel__estimator': [rf], #rf, et, gb, xg\n",
    "            'feat_sel__n_features_to_select': [30]},\n",
    "        {\n",
    "            'feat_sel': [select],\n",
    "            'feat_sel__estimator': [rf]} #rf, et, gb, xg\n",
    "    ]\n",
    "    model_params = [\n",
    "        {\n",
    "            'model': [lr]},\n",
    "        {\n",
    "            'model': [gb],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__learning_rate': [0.1]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "#         {\n",
    "#             'model': [ada],\n",
    "#             'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "#             'model__learning_rate': [0.03], #0.01, 0.04, 0.1, 0.5, 1\n",
    "#             'model__random_state': [9]},\n",
    "        {\n",
    "            'model': [xg],\n",
    "            'model__objective': ['binary:logistic'],\n",
    "            'model__learning_rate': [0.1],   # Learning rate alpha\n",
    "            'model__gamma': [0.1],   # minimum eval_score deduction at each split\n",
    "            'model__min_child_weight': [4],  # minimum number of datapoints in a split\n",
    "            'model__subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "            'model__colsample_bytree': [0.7],  # column-wise sample size\n",
    "            'model__n_estimators': [100]},   # number of trees to build\n",
    "        {\n",
    "            'model': [rf],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7, 9\n",
    "            'model__max_depth': [11]}, #8, 10, 14\n",
    "        {\n",
    "            'model': [et],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7\n",
    "            'model__max_depth': [11]} #8, 10, 14\n",
    "    ]\n",
    "    params = []\n",
    "    for feat_sel in feat_sel_params:\n",
    "        for model in model_params:\n",
    "            # Merge dictionaries and append to list\n",
    "            params.append({**feat_sel, **model})\n",
    "    return pipe, feat_sel_params, model_params, params\n",
    "\n",
    "pipe, feat_params, model_params, all_params = pipeline_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=all_params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).sort_values('rank_test_score').to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_model_combo():\n",
    "    rfe_rf = RFE(RandomForestClassifier(n_estimators=100), step=0.2, n_features_to_select=30)\n",
    "    select_rf = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "    rfe_et = RFE(ExtraTreesClassifier(n_estimators=100), step=0.2, n_features_to_select=30)\n",
    "    select_et = SelectFromModel(ExtraTreesClassifier(n_estimators=100))\n",
    "\n",
    "    rf_gini = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=11, max_features='sqrt',\n",
    "                                     min_samples_leaf=4, n_jobs=-1)\n",
    "    rf_ent = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=11, max_features='sqrt',\n",
    "                                    min_samples_leaf=4, n_jobs=-1)\n",
    "\n",
    "    et_gini = ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=11, max_features='sqrt',\n",
    "                                   min_samples_leaf=4, n_jobs=-1)\n",
    "    et_ent = ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=11, max_features='sqrt',\n",
    "                                  min_samples_leaf=4, n_jobs=-1)\n",
    "\n",
    "    xg = xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    combo = [\n",
    "        # RFE (rf + et + xgb)\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=13, max_features='sqrt',\n",
    "                                     min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=8, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=2, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=6, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=10, max_features='sqrt',\n",
    "                                         min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.7,\n",
    "                                    learning_rate=0.47, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.73, min_child_weight=3, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.7,\n",
    "                                    learning_rate=0.17, min_child_weight=4, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.27, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.7,\n",
    "                                    learning_rate=0.37, min_child_weight=6, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.17, min_child_weight=3, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.7,\n",
    "                                    learning_rate=0.17, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.47, min_child_weight=4, subsample=0.9, n_jobs=-1)},\n",
    "        # SelectFrom Model  (rf + et + xgb)\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=12, max_features='sqrt',\n",
    "                                         min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=12, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=12, max_features='sqrt',\n",
    "                                         min_samples_leaf=2, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=12, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=15, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=15, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=16, max_features='sqrt',\n",
    "                                         min_samples_leaf=4, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=12, max_features='sqrt',\n",
    "                                         min_samples_leaf=6, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=11, max_features='sqrt',\n",
    "                                         min_samples_leaf=8, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=13, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=15, max_features='sqrt',\n",
    "                                         min_samples_leaf=6, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.17,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.22,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.37,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.12,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.37,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.12,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.47,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.12,\n",
    "                                    learning_rate=0.5, min_child_weight=5, subsample=0.9, n_jobs=-1)}\n",
    "    ]\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_mixed(combo, X_train, y_train, X_test, y_test, prob=False):\n",
    "    preds = DataFrame()\n",
    "    preds['y_true'] = y # Check for y and y_test\n",
    "    trained_models = {}\n",
    "    features = X_train.columns.values\n",
    "    \n",
    "    for i, one in zip(range(1, len(combo)+1), combo):\n",
    "        print('\\n')\n",
    "        trained_models[i] = {}\n",
    "        \n",
    "        feat_sel = one['feat_sel']\n",
    "        feat_sel.fit(X_train, y_train)\n",
    "        \n",
    "        imp_feat = [features[i] for i in feat_sel.get_support(indices=True)]\n",
    "        if len(imp_feat)>30:\n",
    "            imp_feat = imp_feat[:30]\n",
    "        print(len(imp_feat))\n",
    "        trained_models[i]['feats'] = imp_feat\n",
    "        \n",
    "        model = one['model']\n",
    "        model.fit(X_train[imp_feat], y_train)\n",
    "        trained_models[i]['model'] = model\n",
    "        \n",
    "        # print(feat_sel, model)\n",
    "        \n",
    "        if prob:\n",
    "            pred = model.predict_proba(X[imp_feat]) # Check for X and X_test   \n",
    "            # preds[key+'_0'] = [i[0] for i in pred]\n",
    "            preds['pred'+str(i)] = [j[1] for j in pred]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            preds['pred'+str(i)] = model.predict(X[imp_feat]) # Check for X and X_test       \n",
    "            print('MCC:', matthews_corrcoef(preds['y_true'], preds['pred'+str(i)]))\n",
    "            print('Acc:', accuracy_score(preds['y_true'], preds['pred'+str(i)]))\n",
    "            print('Confusion Matrix\\n', confusion_matrix(preds['y_true'], preds['pred'+str(i)]))\n",
    "    \n",
    "    if prob:\n",
    "        preds.to_excel('mixed_ensemble_proba.xlsx', index=False)\n",
    "    else:\n",
    "        preds.to_excel('mixed_ensemble_preds.xlsx', index=False)\n",
    "    \n",
    "    return preds, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "30\n",
      "MCC: 0.641312397639\n",
      "Acc: 0.957918442143\n",
      "Confusion Matrix\n",
      " [[41532   701]\n",
      " [ 1205  1855]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.632681140722\n",
      "Acc: 0.956969068068\n",
      "Confusion Matrix\n",
      " [[41515   718]\n",
      " [ 1231  1829]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.64819791728\n",
      "Acc: 0.95864703155\n",
      "Confusion Matrix\n",
      " [[41542   691]\n",
      " [ 1182  1878]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.642857335728\n",
      "Acc: 0.958183383746\n",
      "Confusion Matrix\n",
      " [[41546   687]\n",
      " [ 1207  1853]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.631551918053\n",
      "Acc: 0.956748283399\n",
      "Confusion Matrix\n",
      " [[41502   731]\n",
      " [ 1228  1832]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.630132398096\n",
      "Acc: 0.956946989601\n",
      "Confusion Matrix\n",
      " [[41539   694]\n",
      " [ 1256  1804]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.634996203861\n",
      "Acc: 0.957498951273\n",
      "Confusion Matrix\n",
      " [[41551   682]\n",
      " [ 1243  1817]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.62184259396\n",
      "Acc: 0.956019693992\n",
      "Confusion Matrix\n",
      " [[41520   713]\n",
      " [ 1279  1781]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.627627157974\n",
      "Acc: 0.956682047999\n",
      "Confusion Matrix\n",
      " [[41535   698]\n",
      " [ 1264  1796]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.626710292417\n",
      "Acc: 0.956615812598\n",
      "Confusion Matrix\n",
      " [[41537   696]\n",
      " [ 1269  1791]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.618987325271\n",
      "Acc: 0.955732673923\n",
      "Confusion Matrix\n",
      " [[41517   716]\n",
      " [ 1289  1771]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.625647443911\n",
      "Acc: 0.95652749873\n",
      "Confusion Matrix\n",
      " [[41538   695]\n",
      " [ 1274  1786]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.782512126629\n",
      "Acc: 0.97374870289\n",
      "Confusion Matrix\n",
      " [[41796   437]\n",
      " [  752  2308]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.856321919484\n",
      "Acc: 0.982447618837\n",
      "Confusion Matrix\n",
      " [[41953   280]\n",
      " [  515  2545]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.734373561786\n",
      "Acc: 0.968096615371\n",
      "Confusion Matrix\n",
      " [[41682   551]\n",
      " [  894  2166]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.760343910357\n",
      "Acc: 0.9712096792\n",
      "Confusion Matrix\n",
      " [[41755   478]\n",
      " [  826  2234]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.749504922781\n",
      "Acc: 0.970105755856\n",
      "Confusion Matrix\n",
      " [[41756   477]\n",
      " [  877  2183]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.7200440396\n",
      "Acc: 0.966661515024\n",
      "Confusion Matrix\n",
      " [[41682   551]\n",
      " [  959  2101]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.719292132827\n",
      "Acc: 0.966418651889\n",
      "Confusion Matrix\n",
      " [[41658   575]\n",
      " [  946  2114]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.821590774033\n",
      "Acc: 0.978429337867\n",
      "Confusion Matrix\n",
      " [[41902   331]\n",
      " [  646  2414]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.583642318463\n",
      "Acc: 0.954584593646\n",
      "Confusion Matrix\n",
      " [[41750   483]\n",
      " [ 1574  1486]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.573457430899\n",
      "Acc: 0.953546905703\n",
      "Confusion Matrix\n",
      " [[41727   506]\n",
      " [ 1598  1462]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.607123665629\n",
      "Acc: 0.956704126465\n",
      "Confusion Matrix\n",
      " [[41764   469]\n",
      " [ 1492  1568]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.575258054495\n",
      "Acc: 0.953745611905\n",
      "Confusion Matrix\n",
      " [[41733   500]\n",
      " [ 1595  1465]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.584455565804\n",
      "Acc: 0.954452122845\n",
      "Confusion Matrix\n",
      " [[41724   509]\n",
      " [ 1554  1506]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.640561475054\n",
      "Acc: 0.95970679796\n",
      "Confusion Matrix\n",
      " [[41769   464]\n",
      " [ 1361  1699]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.629126849035\n",
      "Acc: 0.95858079615\n",
      "Confusion Matrix\n",
      " [[41755   478]\n",
      " [ 1398  1662]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.569297912327\n",
      "Acc: 0.953326121034\n",
      "Confusion Matrix\n",
      " [[41743   490]\n",
      " [ 1624  1436]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.551611813936\n",
      "Acc: 0.951935177621\n",
      "Confusion Matrix\n",
      " [[41751   482]\n",
      " [ 1695  1365]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.586910246235\n",
      "Acc: 0.954739142914\n",
      "Confusion Matrix\n",
      " [[41734   499]\n",
      " [ 1551  1509]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.591753297364\n",
      "Acc: 0.955114476851\n",
      "Confusion Matrix\n",
      " [[41729   504]\n",
      " [ 1529  1531]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.597386386396\n",
      "Acc: 0.955622281589\n",
      "Confusion Matrix\n",
      " [[41732   501]\n",
      " [ 1509  1551]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.765609327915\n",
      "Acc: 0.97233568101\n",
      "Confusion Matrix\n",
      " [[41862   371]\n",
      " [  882  2178]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.759488545685\n",
      "Acc: 0.971673327004\n",
      "Confusion Matrix\n",
      " [[41855   378]\n",
      " [  905  2155]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.785830925124\n",
      "Acc: 0.974653920032\n",
      "Confusion Matrix\n",
      " [[41910   323]\n",
      " [  825  2235]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.785279822061\n",
      "Acc: 0.974587684631\n",
      "Confusion Matrix\n",
      " [[41908   325]\n",
      " [  826  2234]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.758140981398\n",
      "Acc: 0.971474620802\n",
      "Confusion Matrix\n",
      " [[41843   390]\n",
      " [  902  2158]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.755913653686\n",
      "Acc: 0.971231757667\n",
      "Confusion Matrix\n",
      " [[41840   393]\n",
      " [  910  2150]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.79480580085\n",
      "Acc: 0.975647451041\n",
      "Confusion Matrix\n",
      " [[41922   311]\n",
      " [  792  2268]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.785279822061\n",
      "Acc: 0.974587684631\n",
      "Confusion Matrix\n",
      " [[41908   325]\n",
      " [  826  2234]]\n"
     ]
    }
   ],
   "source": [
    "models_combo = feat_model_combo()\n",
    "pred_all, trained_models = predict_mixed(models_combo, X_train, y_train, X_test, y_test, False) # Probability True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    et = ExtraTreesClassifier(n_estimators=100)\n",
    "    xg = xgb.XGBClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100)\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    models = {\n",
    "        'rf': rf,\n",
    "        'lr': lr,\n",
    "        'xg': xg,\n",
    "        'et': et,\n",
    "        'gb': gb,\n",
    "        'ada': ada\n",
    "    }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_uni(models, X_train, y_train, X_test, y_test, prob=False):\n",
    "    preds = DataFrame()\n",
    "    preds['y_true'] = y # Check for y and y_test\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        print('\\n', key)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[key] = model\n",
    "        \n",
    "        if prob:\n",
    "            pred = model.predict_proba(X) # Check for X and X_test   \n",
    "            # preds[key+'_0'] = [i[0] for i in pred]\n",
    "            preds[key+'_1'] = [i[1] for i in pred]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            preds[key] = model.predict(X) # Check for X and X_test       \n",
    "            print('MCC:', matthews_corrcoef(preds['y_true'], preds[key]))\n",
    "            print('Acc:', accuracy_score(preds['y_true'], preds[key]))\n",
    "            print('Confusion Matrix\\n', confusion_matrix(preds['y_true'], preds[key]))\n",
    "    \n",
    "    if prob:\n",
    "        preds.to_excel('uni_ensemble_proba.xlsx', index=False)\n",
    "    else:\n",
    "        preds.to_excel('uni_ensemble_preds.xlsx', index=False)\n",
    "    \n",
    "    return preds, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "pred_all, trained_models = predict_uni(models, X_train, y_train, X_test, y_test, True) # Probability True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.670441920339\n",
      "Acc: 0.962444527852\n",
      "Confusion Matrix\n",
      " [[41767   466]\n",
      " [ 1235  1825]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nanmean\n",
    "\n",
    "pred_all['final'] = pred_all.loc[:,'pred1':('pred'+str(len(models_combo)))].apply(lambda row: round(nanmean(row.values)), axis=1)\n",
    "\n",
    "print('MCC:', matthews_corrcoef(pred_all['y_true'], pred_all['final']))\n",
    "print('Acc:', accuracy_score(pred_all['y_true'], pred_all['final']))\n",
    "print('Confusion Matrix\\n', confusion_matrix(pred_all['y_true'], pred_all['final']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred31</th>\n",
       "      <th>pred32</th>\n",
       "      <th>pred33</th>\n",
       "      <th>pred34</th>\n",
       "      <th>pred35</th>\n",
       "      <th>pred36</th>\n",
       "      <th>pred37</th>\n",
       "      <th>pred38</th>\n",
       "      <th>pred39</th>\n",
       "      <th>pred40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true  pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  \\\n",
       "0       0      0      0      0      0      0      0      0      0      0   \n",
       "1       1      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
       "0   ...         0       0       0       0       0       0       0       0   \n",
       "1   ...         0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pred39  pred40  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "pred_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metalearner on Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
      "0      0      0      0      0      0      0      0      0      0       0   \n",
      "1      0      0      0      0      0      0      0      0      0       0   \n",
      "\n",
      "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
      "0   ...         0       0       0       0       0       0       0       0   \n",
      "1   ...         0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pred39  pred40  \n",
      "0       0       0  \n",
      "1       0       0  \n",
      "\n",
      "[2 rows x 40 columns]\n",
      "\n",
      " (45247, 40) (46, 40)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y_m = pred_all['y_true']\n",
    "X_m = pred_all.drop('y_true', axis=1)\n",
    "print(X_m.head(2))\n",
    "\n",
    "# Splitting Train test\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, stratify=y_m, test_size=0.001, random_state=20)\n",
    "print('\\n', X_train_m.shape, X_test_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  21 | elapsed:   29.0s remaining:    9.0s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  21 | elapsed:   32.0s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   32.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'model': [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)]}, {'model':...tropy'], 'model__max_features': ['sqrt'], 'model__min_samples_leaf': [4], 'model__max_depth': [11]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=20)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_pipe = Pipeline([('model', RandomForestClassifier())])\n",
    "meta_grid = GridSearchCV(estimator=meta_pipe, param_grid=model_params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "meta_grid.fit(X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = meta_grid.best_estimator_.fit(X_train_m, y_train_m)\n",
    "meta_pred = meta_model.predict(X_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 1.0\n",
      "Acc: 1.0\n",
      "Confusion Matrix\n",
      " [[43  0]\n",
      " [ 0  3]]\n"
     ]
    }
   ],
   "source": [
    "print('MCC:', matthews_corrcoef(y_test_m, meta_pred))\n",
    "print('Acc:', accuracy_score(y_test_m, meta_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test_m, meta_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = MLPClassifier((100, 25), max_iter=200,tol=0, verbose=10)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = nn\n",
    "y_pred = best_model.predict(X_test)\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.03],   # Learning rate alpha\n",
    "    'max_depth': [10],   # maximum depth of the tree\n",
    "    'gamma': [0.1, 0.5],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [3, 6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [100],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=50, scoring=make_scorer(matthews_corrcoef), n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imp_feats = X_train.columns.values[grid.best_params_.get_support(indices=True)]\n",
    "# print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "xgb_model = grid.best_estimator_.fit(X_train, y_train) #[imp_feats]\n",
    "y_pred = xgb_model.predict(X_test) #[imp_feats]\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    #'num_class': 2     # num_class not required with the Binary Logistic\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "from numpy import linspace, array\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    thresholds = linspace(0.01, 0.99, 50)\n",
    "    mcc = array([matthews_corrcoef(labels, preds>thr) for thr in thresholds])\n",
    "    best_score = mcc.max()\n",
    "    return 'mcc', -best_score\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, feval = evalerror, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  66583679        4       0.0         4         1         2         1   \n",
      "1  35494679        4       0.0         4         1         1         1   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY  ...    POVERTY3  TOOLONG  TROUBUND  PDEN10  \\\n",
      "0         1         1        99  ...         2.0        2         2       1   \n",
      "1         1         1        99  ...         3.0        2         2       1   \n",
      "\n",
      "   COUTYP2  MAIIN102  AIIND102      ANALWT_C  VESTR  VEREP  \n",
      "0        1         2         2  16346.795400  40020      1  \n",
      "1        1         2         2   3008.863906  40044      2  \n",
      "\n",
      "[2 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv', na_values=-1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n",
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n",
      "   IRKI17_2  IRHH65_2  IRWELMOS      ANALWT_C  NC17  IFATHER_freq  IFATHER_1  \\\n",
      "0         2         1        99  16346.795400   0.0      0.058072          0   \n",
      "1         1         1        99   3008.863906   0.0      0.058072          0   \n",
      "\n",
      "   IFATHER_2  IFATHER_3  IFATHER_4     ...      HLNV_freq  HLNV_15  HLNV_20  \\\n",
      "0          0          0          1     ...       0.067787        0        0   \n",
      "1          0          0          1     ...       0.067787        0        0   \n",
      "\n",
      "   HLNV_25  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  HLCALL_2  HLCALL_196  \n",
      "0        0         0         0         1     0.067419         0           1  \n",
      "1        0         0         0         1     0.067419         0           1  \n",
      "\n",
      "[2 rows x 317 columns]\n"
     ]
    }
   ],
   "source": [
    "perid = test['PERID']\n",
    "test.drop('PERID', axis=1, inplace=True)\n",
    "\n",
    "from numpy import inf, nan\n",
    "test = test.replace([inf, -inf, nan], 0).fillna(0)\n",
    "\n",
    "test['NC17'] = test['NRCH17_2'] / test['IRHHSIZ2']\n",
    "del test['NRCH17_2']\n",
    "del test['IRHHSIZ2']\n",
    "\n",
    "hlnv_cols = [col for col in test.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "test['HLNV'] = test[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in test.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "test['HLCALL'] = test[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlcall_cols, axis=1)\n",
    "\n",
    "test['HLCNOTMO'] = test['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "test['HLCLAST'] = test['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)\n",
    "\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in test.columns.values if col not in num_cols]\n",
    "\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    test[col+'_freq'] = test[col].map(freqs[col]['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    test[col] = test[col].astype('category',copy=False)\n",
    "    temp = get_dummies(test[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    test = test.join(temp)\n",
    "    test = test.drop(col,axis=1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level-1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(0)\n",
    "meta_test = DataFrame()\n",
    "\n",
    "for i, dic in trained_models.items():\n",
    "    meta_test['pred'+str(i)] = dic['model'].predict(test[dic['feats']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>...</th>\n",
       "      <th>pred31</th>\n",
       "      <th>pred32</th>\n",
       "      <th>pred33</th>\n",
       "      <th>pred34</th>\n",
       "      <th>pred35</th>\n",
       "      <th>pred36</th>\n",
       "      <th>pred37</th>\n",
       "      <th>pred38</th>\n",
       "      <th>pred39</th>\n",
       "      <th>pred40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
       "0   ...         0       0       0       0       0       0       0       0   \n",
       "1   ...         0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pred39  pred40  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
      "0      0      0      0      0      0      0      0      0      0       0   \n",
      "1      0      0      0      0      0      0      0      0      0       0   \n",
      "\n",
      "     ...     pred33  pred34  pred35  pred36  pred37  pred38  pred39  pred40  \\\n",
      "0    ...          0       0       0       0       0       0       0       0   \n",
      "1    ...          0       0       0       0       0       0       0       0   \n",
      "\n",
      "   Criminal     PERID  \n",
      "0         0  66583679  \n",
      "1         0  35494679  \n",
      "\n",
      "[2 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "meta_test['Criminal'] = meta_model.predict(meta_test)\n",
    "meta_test['PERID'] = perid\n",
    "print(meta_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_test[['PERID', 'Criminal']].to_csv('final_15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criminal  number: 777, percent: 0.06797900262467192\n"
     ]
    }
   ],
   "source": [
    "nc = sum(meta_test['Criminal'])\n",
    "print('Criminal  number: {}, percent: {}'.format(nc, nc / meta_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in imp_feats:\n",
    "    if f not in test.columns.values:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
