{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA',\n",
       "       'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN',\n",
       "       'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN',\n",
       "       'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR',\n",
       "       'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS',\n",
       "       'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4',\n",
       "       'OTHINS', 'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC',\n",
       "       'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT',\n",
       "       'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS',\n",
       "       'IRPINC3', 'IRFAMIN3', 'IIPINC3', 'IIFAMIN3', 'GOVTPROG',\n",
       "       'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP2', 'MAIIN102',\n",
       "       'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP', 'Criminal'], dtype=object)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "from numpy import inf, nan\n",
    "train = train.replace([inf, -inf], nan).dropna()\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "\n",
      " IFATHER\n",
      "      Overall  Criminal\n",
      "4.0  0.760758  0.653922\n",
      "1.0  0.171726  0.200000\n",
      "2.0  0.067339  0.145425\n",
      "3.0  0.000177  0.000654\n",
      "\n",
      " NRCH17_2\n",
      "      Overall  Criminal\n",
      "0.0  0.731548  0.889869\n",
      "1.0  0.110370  0.051634\n",
      "2.0  0.101804  0.037582\n",
      "3.0  0.056278  0.020915\n",
      "\n",
      " IRHHSIZ2\n",
      "      Overall  Criminal\n",
      "1.0  0.078489  0.139869\n",
      "2.0  0.222639  0.267974\n",
      "3.0  0.223147  0.217320\n",
      "4.0  0.239309  0.191503\n",
      "5.0  0.136003  0.101634\n",
      "6.0  0.100413  0.081699\n",
      "\n",
      " IIHHSIZ2\n",
      "     Overall  Criminal\n",
      "1.0      1.0       1.0\n",
      "\n",
      " IRKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.417084  0.494771\n",
      "2.0  0.223015  0.191176\n",
      "3.0  0.210695  0.176797\n",
      "4.0  0.149206  0.137255\n",
      "\n",
      " IIKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.997726  0.997712\n",
      "3.0  0.002274  0.002288\n",
      "\n",
      " IRHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.878193  0.741503\n",
      "2.0  0.079725  0.149346\n",
      "3.0  0.042082  0.109150\n",
      "\n",
      " IIHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.995474  0.995425\n",
      "3.0  0.004018  0.004248\n",
      "2.0  0.000508  0.000327\n",
      "\n",
      " PRXRETRY\n",
      "       Overall  Criminal\n",
      "2.0   0.016603  0.014706\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000110       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.982359  0.983987\n",
      "\n",
      " PRXYDATA\n",
      "       Overall  Criminal\n",
      "1.0   0.288676  0.363399\n",
      "2.0   0.000839  0.000654\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000066       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.709492  0.634641\n",
      "\n",
      " MEDICARE\n",
      "       Overall  Criminal\n",
      "2.0   0.912106  0.750327\n",
      "1.0   0.083567  0.236601\n",
      "94.0  0.003466  0.010131\n",
      "97.0  0.000773  0.002288\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " CAIDCHIP\n",
      "       Overall  Criminal\n",
      "1.0   0.225377  0.092484\n",
      "2.0   0.765659  0.882353\n",
      "85.0  0.001126  0.001307\n",
      "94.0  0.006911  0.020588\n",
      "97.0  0.000927  0.003268\n",
      "\n",
      " CHAMPUS\n",
      "       Overall  Criminal\n",
      "2.0   0.959817  0.962418\n",
      "1.0   0.037931  0.028105\n",
      "94.0  0.001590  0.006863\n",
      "97.0  0.000574  0.001961\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " PRVHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.607644  0.962418\n",
      "2.0   0.385932       NaN\n",
      "85.0  0.000088  0.000654\n",
      "94.0  0.005431  0.033007\n",
      "97.0  0.000905  0.003922\n",
      "\n",
      " GRPHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.535712  0.731373\n",
      "2.0   0.070386  0.224183\n",
      "85.0  0.000066  0.000327\n",
      "94.0  0.001523  0.006536\n",
      "97.0  0.000927  0.004248\n",
      "98.0  0.005453  0.033333\n",
      "99.0  0.385932       NaN\n",
      "\n",
      " HLTINNOS\n",
      "       Overall  Criminal\n",
      "1.0   0.031175       NaN\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.000486       NaN\n",
      "97.0  0.000132       NaN\n",
      "99.0  0.866028       1.0\n",
      "\n",
      " HLCNOTYR\n",
      "       Overall  Criminal\n",
      "1.0   0.071777  0.054575\n",
      "2.0   0.815402  0.914706\n",
      "85.0  0.000464  0.000654\n",
      "94.0  0.001943  0.004902\n",
      "97.0  0.001170  0.003595\n",
      "98.0  0.007065  0.021569\n",
      "99.0  0.102179       NaN\n",
      "\n",
      " HLCLAST\n",
      "       Overall  Criminal\n",
      "1.0   0.019208       NaN\n",
      "2.0   0.012320       NaN\n",
      "3.0   0.021063       NaN\n",
      "4.0   0.028967       NaN\n",
      "5.0   0.019849       NaN\n",
      "94.0  0.000729       NaN\n",
      "97.0  0.001192  0.003268\n",
      "98.0  0.007529  0.022222\n",
      "99.0  0.889144  0.974510\n",
      "\n",
      " HLNVCOST\n",
      "       Overall  Criminal\n",
      "1.0   0.009913       NaN\n",
      "6.0   0.009869       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVOFFR\n",
      "       Overall  Criminal\n",
      "1.0   0.002914       NaN\n",
      "6.0   0.016868       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVREF\n",
      "       Overall  Criminal\n",
      "1.0   0.000596       NaN\n",
      "6.0   0.019186       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVNEED\n",
      "       Overall  Criminal\n",
      "1.0   0.003974       NaN\n",
      "6.0   0.015808       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVSOR\n",
      "       Overall  Criminal\n",
      "1.0   0.002936       NaN\n",
      "6.0   0.016846       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " IRMCDCHP\n",
      "     Overall  Criminal\n",
      "2.0  0.77151  0.895425\n",
      "1.0  0.22849  0.104575\n",
      "\n",
      " IIMCDCHP\n",
      "      Overall  Criminal\n",
      "1.0  0.991036  0.974837\n",
      "3.0  0.008964  0.025163\n",
      "\n",
      " IRMEDICR\n",
      "      Overall  Criminal\n",
      "2.0  0.916256  0.762745\n",
      "1.0  0.083744  0.237255\n",
      "\n",
      " IIMEDICR\n",
      "      Overall  Criminal\n",
      "1.0  0.995673  0.986928\n",
      "3.0  0.004327  0.013072\n",
      "\n",
      " IRCHMPUS\n",
      "      Overall  Criminal\n",
      "2.0  0.962025  0.971895\n",
      "1.0  0.037975  0.028105\n",
      "\n",
      " IICHMPUS\n",
      "      Overall  Criminal\n",
      "1.0  0.997748  0.990523\n",
      "3.0  0.002252  0.009477\n",
      "\n",
      " IRPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.611044  0.977778\n",
      "2.0  0.388956  0.022222\n",
      "\n",
      " IIPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.993575  0.962418\n",
      "3.0  0.006425  0.037582\n",
      "\n",
      " IROTHHLT\n",
      "       Overall  Criminal\n",
      "99.0  0.863489  0.994444\n",
      "2.0   0.104564  0.004575\n",
      "1.0   0.031948  0.000980\n",
      "\n",
      " IIOTHHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.133354       NaN\n",
      "3.0  0.008677   0.02549\n",
      "9.0  0.857969   0.97451\n",
      "\n",
      " HLCALLFG\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " HLCALL99\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " ANYHLTI2\n",
      "       Overall  Criminal\n",
      "1.0   0.889144  0.974510\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.007043  0.021569\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.000486  0.000654\n",
      "\n",
      " IRINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.895436  0.995425\n",
      "2.0  0.104564  0.004575\n",
      "\n",
      " IIINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.991323   0.97451\n",
      "3.0  0.008677   0.02549\n",
      "\n",
      " OTHINS\n",
      "     Overall  Criminal\n",
      "2.0   0.8549  0.749673\n",
      "1.0   0.1451  0.250327\n",
      "\n",
      " CELLNOTCL\n",
      "       Overall  Criminal\n",
      "1.0   0.433312  0.477451\n",
      "2.0   0.565385  0.520588\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000442  0.000327\n",
      "97.0  0.000640  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " CELLWRKNG\n",
      "       Overall  Criminal\n",
      "1.0   0.977016  0.952614\n",
      "2.0   0.022255  0.045425\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000110  0.000327\n",
      "97.0  0.000397  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " IRFAMSOC\n",
      "      Overall  Criminal\n",
      "2.0  0.836796  0.677778\n",
      "1.0  0.163204  0.322222\n",
      "\n",
      " IIFAMSOC\n",
      "      Overall  Criminal\n",
      "1.0  0.991213  0.982026\n",
      "3.0  0.008787  0.017974\n",
      "\n",
      " IRFAMSSI\n",
      "      Overall  Criminal\n",
      "2.0  0.931446  0.926471\n",
      "1.0  0.068554  0.073529\n",
      "\n",
      " IIFAMSSI\n",
      "      Overall  Criminal\n",
      "1.0  0.991058  0.977778\n",
      "3.0  0.008942  0.022222\n",
      "\n",
      " IRFSTAMP\n",
      "      Overall  Criminal\n",
      "2.0  0.798931  0.807516\n",
      "1.0  0.201069  0.192484\n",
      "\n",
      " IIFSTAMP\n",
      "      Overall  Criminal\n",
      "1.0  0.995584  0.989869\n",
      "3.0  0.004416  0.010131\n",
      "\n",
      " IRFAMPMT\n",
      "      Overall  Criminal\n",
      "2.0  0.973197  0.975163\n",
      "1.0  0.026803  0.024837\n",
      "\n",
      " IIFAMPMT\n",
      "      Overall  Criminal\n",
      "1.0  0.993134   0.98268\n",
      "3.0  0.006866   0.01732\n",
      "\n",
      " IRFAMSVC\n",
      "      Overall  Criminal\n",
      "2.0  0.963858  0.962418\n",
      "1.0  0.036142  0.037582\n",
      "\n",
      " IIFAMSVC\n",
      "      Overall  Criminal\n",
      "1.0  0.994922  0.985621\n",
      "3.0  0.005078  0.014379\n",
      "\n",
      " IIWELMOS\n",
      "      Overall  Criminal\n",
      "9.0  0.938379  0.927124\n",
      "1.0  0.052149  0.050000\n",
      "3.0  0.009472  0.022876\n",
      "\n",
      " IRPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.468549  0.632026\n",
      "2.0  0.157132  0.181046\n",
      "3.0  0.099773  0.102941\n",
      "4.0  0.072506  0.053922\n",
      "5.0  0.058817  0.030065\n",
      "6.0  0.073102       NaN\n",
      "7.0  0.070121       NaN\n",
      "\n",
      " IRFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.082551  0.128431\n",
      "2.0  0.122248  0.166013\n",
      "3.0  0.110790  0.211765\n",
      "4.0  0.105248  0.240523\n",
      "5.0  0.099508  0.253268\n",
      "6.0  0.157022       NaN\n",
      "7.0  0.322633       NaN\n",
      "\n",
      " IIPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.969907  0.950654\n",
      "3.0  0.030093  0.049346\n",
      "\n",
      " IIFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.903385  0.860458\n",
      "3.0  0.096615  0.139542\n",
      "\n",
      " GOVTPROG\n",
      "      Overall  Criminal\n",
      "2.0  0.761332  0.757843\n",
      "1.0  0.238668  0.242157\n",
      "\n",
      " POVERTY3\n",
      "      Overall  Criminal\n",
      "1.0  0.205551   0.27451\n",
      "2.0  0.225289   0.47451\n",
      "3.0  0.569161   0.25098\n",
      "\n",
      " TOOLONG\n",
      "       Overall  Criminal\n",
      "2.0   0.924779  0.899673\n",
      "1.0   0.072594  0.097059\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " TROUBUND\n",
      "       Overall  Criminal\n",
      "2.0   0.940388  0.917320\n",
      "1.0   0.056985  0.079412\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " PDEN10\n",
      "      Overall  Criminal\n",
      "2.0  0.490584  0.538889\n",
      "1.0  0.432142  0.369608\n",
      "3.0  0.077275  0.091503\n",
      "\n",
      " COUTYP2\n",
      "      Overall  Criminal\n",
      "1.0  0.443976  0.383987\n",
      "2.0  0.348509  0.375817\n",
      "3.0  0.207516  0.240196\n",
      "\n",
      " MAIIN102\n",
      "      Overall  Criminal\n",
      "2.0  0.978915  0.979739\n",
      "1.0  0.021085  0.020261\n",
      "\n",
      " AIIND102\n",
      "      Overall  Criminal\n",
      "2.0  0.978716  0.979085\n",
      "1.0  0.021284  0.020915\n",
      "\n",
      " VEREP\n",
      "      Overall  Criminal\n",
      "1.0  0.506414  0.519608\n",
      "2.0  0.493586  0.480392\n",
      "\n",
      " Criminal\n",
      "   Overall  Criminal\n",
      "0  0.93244       NaN\n",
      "1  0.06756       1.0\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "overall = train.shape[0]\n",
    "train_criminal = train[train['Criminal']==1]\n",
    "criminal = train_criminal.shape[0]\n",
    "for col in cols:\n",
    "    if len(train[col].unique()) > 10:\n",
    "        continue\n",
    "    print('\\n', col)\n",
    "    temp = DataFrame({'Overall': train[col].value_counts() / overall,\n",
    "                      'Criminal': train_criminal[col].value_counts() / criminal})\n",
    "    print(temp[['Overall', 'Criminal']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating \"NC17\" column by removing (NRCH17_2, IRHHSIZ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NC17'] = train['NRCH17_2'] / train['IRHHSIZ2']\n",
    "del train['NRCH17_2']\n",
    "del train['IRHHSIZ2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining \"HLNV\" columns   and   \"HLCALL\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n"
     ]
    }
   ],
   "source": [
    "hlnv_cols = [col for col in train.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "train['HLNV'] = train[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in train.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "train['HLCALL'] = train[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlcall_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming \"HLCNOTMO\"  and  \"HLCLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['HLCNOTMO'] = train['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "train['HLCLAST'] = train['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 5 59\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFATHER\n",
      "IIHHSIZ2\n",
      "IIKI17_2\n",
      "IIHH65_2\n",
      "PRXRETRY\n",
      "PRXYDATA\n",
      "MEDICARE\n",
      "CAIDCHIP\n",
      "CHAMPUS\n",
      "PRVHLTIN\n",
      "GRPHLTIN\n",
      "HLTINNOS\n",
      "HLCNOTYR\n",
      "HLCNOTMO\n",
      "HLCLAST\n",
      "HLLOSRSN\n",
      "IRMCDCHP\n",
      "IIMCDCHP\n",
      "IRMEDICR\n",
      "IIMEDICR\n",
      "IRCHMPUS\n",
      "IICHMPUS\n",
      "IRPRVHLT\n",
      "IIPRVHLT\n",
      "IROTHHLT\n",
      "IIOTHHLT\n",
      "ANYHLTI2\n",
      "IRINSUR4\n",
      "IIINSUR4\n",
      "OTHINS\n",
      "CELLNOTCL\n",
      "CELLWRKNG\n",
      "IRFAMSOC\n",
      "IIFAMSOC\n",
      "IRFAMSSI\n",
      "IIFAMSSI\n",
      "IRFSTAMP\n",
      "IIFSTAMP\n",
      "IRFAMPMT\n",
      "IIFAMPMT\n",
      "IRFAMSVC\n",
      "IIFAMSVC\n",
      "IIWELMOS\n",
      "IRPINC3\n",
      "IRFAMIN3\n",
      "IIPINC3\n",
      "IIFAMIN3\n",
      "GOVTPROG\n",
      "POVERTY3\n",
      "TOOLONG\n",
      "TROUBUND\n",
      "PDEN10\n",
      "COUTYP2\n",
      "MAIIN102\n",
      "AIIND102\n",
      "VESTR\n",
      "VEREP\n",
      "HLNV\n",
      "HLCALL\n"
     ]
    }
   ],
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "for col in cat_cols:\n",
    "    train[col] = train[col].astype('category',copy=False)\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i) for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>NC17</th>\n",
       "      <th>IFATHER_1.0</th>\n",
       "      <th>IFATHER_2.0</th>\n",
       "      <th>IFATHER_3.0</th>\n",
       "      <th>IFATHER_4.0</th>\n",
       "      <th>...</th>\n",
       "      <th>VEREP_2.0</th>\n",
       "      <th>HLNV_15.0</th>\n",
       "      <th>HLNV_20.0</th>\n",
       "      <th>HLNV_25.0</th>\n",
       "      <th>HLNV_470.0</th>\n",
       "      <th>HLNV_485.0</th>\n",
       "      <th>HLNV_490.0</th>\n",
       "      <th>HLNV_495.0</th>\n",
       "      <th>HLCALL_2.0</th>\n",
       "      <th>HLCALL_196.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IRKI17_2  IRHH65_2  IRWELMOS     ANALWT_C  Criminal      NC17  IFATHER_1.0  \\\n",
       "0       3.0       1.0      99.0  3884.805998         0  0.500000            0   \n",
       "1       2.0       1.0      99.0  1627.108106         1  0.333333            0   \n",
       "\n",
       "   IFATHER_2.0  IFATHER_3.0  IFATHER_4.0      ...       VEREP_2.0  HLNV_15.0  \\\n",
       "0            0            0            1      ...               0          0   \n",
       "1            0            0            1      ...               1          0   \n",
       "\n",
       "   HLNV_20.0  HLNV_25.0  HLNV_470.0  HLNV_485.0  HLNV_490.0  HLNV_495.0  \\\n",
       "0          0          0           0           0           0           1   \n",
       "1          0          0           0           0           0           1   \n",
       "\n",
       "   HLCALL_2.0  HLCALL_196.0  \n",
       "0           0             1  \n",
       "1           0             1  \n",
       "\n",
       "[2 rows x 255 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X['download_time'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing Multicollinearity (using VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "from numpy import arange, delete\n",
    "\n",
    "def calculate_vif(X, thresh=100):\n",
    "    cols = X.columns\n",
    "    variables = arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-15b1bb3aa044>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_vif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-4c5284e6656a>\u001b[0m in \u001b[0;36mcalculate_vif\u001b[1;34m(X, thresh)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdropped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mvif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmaxloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvif\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-4c5284e6656a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdropped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mvif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvariance_inflation_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmaxloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvif\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvif\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py\u001b[0m in \u001b[0;36mvariance_inflation_factor\u001b[1;34m(exog, exog_idx)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_vars\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexog_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mx_noti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mr_squared_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_noti\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrsquared\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[0mvif\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mr_squared_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvif\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, method, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 (not hasattr(self, 'rank'))):\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpinv_wexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msingular_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpinv_extended\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m                 self.normalized_cov_params = np.dot(self.pinv_wexog,\n\u001b[0;32m    192\u001b[0m                                         np.transpose(self.pinv_wexog))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\tools.py\u001b[0m in \u001b[0;36mpinv_extended\u001b[1;34m(X, rcond)\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m     \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[0ms_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m         \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->DdD'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->ddd'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m         \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m         \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = calculate_vif(X, 10)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31705, 254) (13588, 254)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=15)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(X_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAIlCAYAAADrKl//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGo1GD7RAu9FoNBqNRqPR6IH/AyB3QUjWSYo4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2788028af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp[:20].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(12,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ANALWT_C', 'POVERTY3_3.0', 'IRFAMIN3_7.0', 'IRFAMIN3_6.0', 'IRPINC3_1.0', 'IRFAMIN3_5.0', 'POVERTY3_2.0', 'IRFAMIN3_4.0', 'IFATHER_4.0', 'IRKI17_2', 'PRVHLTIN_2.0', 'POVERTY3_1.0', 'GRPHLTIN_99.0', 'IRPRVHLT_1.0', 'IRFAMIN3_3.0', 'IRPRVHLT_2.0', 'GRPHLTIN_2.0', 'NC17', 'PRXYDATA_1.0', 'VEREP_1.0']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = list(feat_imp[:20].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "et = ExtraTreesClassifier()\n",
    "ada = AdaBoostClassifier(base_estimator=et)\n",
    "gb = GradientBoostingClassifier()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfe = RFE(rf, step=0.2)\n",
    "select = SelectFromModel(rf)\n",
    "kbest = SelectKBest(chi2)\n",
    "\n",
    "pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "\n",
    "feat_sel_params = [\n",
    "    {\n",
    "        'feat_sel': [kbest],\n",
    "        'feat_sel__k': [20, 30]},\n",
    "    {\n",
    "        'feat_sel': [rfe],\n",
    "        'feat_sel__estimator': [gb], #rf, et, \n",
    "        'feat_sel__n_features_to_select': [20]},\n",
    "    {\n",
    "        'feat_sel': [select],\n",
    "        'feat_sel__estimator': [gb]} #rf, et, \n",
    "]\n",
    "\n",
    "model_params = [\n",
    "    {\n",
    "        'model': [lr]},\n",
    "    {\n",
    "        'model': [gb],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.5]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "    {\n",
    "        'model': [ada],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__learning_rate': [0.5], #0.01, 0.04, 0.1, 0.5, 1\n",
    "        'model__random_state': [2]},\n",
    "    {\n",
    "        'model': [rf],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7, 9\n",
    "        'model__max_depth': [9]}, #8, 10, 14\n",
    "    {\n",
    "        'model': [et],\n",
    "        'model__n_estimators': [20], #500, 1000, 2000, 4000\n",
    "        'model__criterion': ['gini', 'entropy'],\n",
    "        'model__max_features': ['sqrt'], #, 'log2'\n",
    "        'model__min_samples_leaf': [3], #3, 5, 7\n",
    "        'model__max_depth': [9]} #8, 10, 14\n",
    "]\n",
    "\n",
    "params = []\n",
    "for feat_sel in feat_sel_params:\n",
    "    for model in model_params:\n",
    "        # Merge dictionaries and append to list\n",
    "        params.append({**feat_sel, **model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:   18.2s\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   57.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 out of  84 | elapsed:  9.1min remaining:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:  9.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('feat_sel', RFE(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "   ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'feat_sel': [SelectKBest(k=10, score_func=<function chi2 at 0x00000278FB05A7B8>)], 'feat_sel__k': [20, 30], 'model': [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty=...ntropy'], 'model__max_features': ['sqrt'], 'model__min_samples_leaf': [3], 'model__max_depth': [9]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=20)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591819372603\n",
      "Pipeline(memory=None,\n",
      "     steps=[('feat_sel', SelectFromModel(estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "       ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False))])\n"
     ]
    }
   ],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).sort_values('rank_test_score').to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IRKI17_2' 'ANALWT_C' 'NC17' 'IFATHER_2.0' 'IFATHER_4.0' 'PRXYDATA_1.0'\n",
      " 'MEDICARE_2.0' 'CHAMPUS_85.0' 'PRVHLTIN_1.0' 'PRVHLTIN_2.0'\n",
      " 'PRVHLTIN_94.0' 'GRPHLTIN_1.0' 'GRPHLTIN_2.0' 'GRPHLTIN_94.0'\n",
      " 'GRPHLTIN_97.0' 'GRPHLTIN_98.0' 'GRPHLTIN_99.0' 'HLCNOTYR_1.0'\n",
      " 'IRMEDICR_1.0' 'IRMEDICR_2.0' 'CELLWRKNG_94.0' 'IRFAMSOC_1.0'\n",
      " 'IIFAMSSI_3.0' 'IRPINC3_1.0' 'IRPINC3_2.0' 'IRPINC3_4.0' 'IRFAMIN3_1.0'\n",
      " 'IRFAMIN3_2.0' 'IRFAMIN3_3.0' 'IRFAMIN3_4.0' 'IRFAMIN3_5.0' 'IRFAMIN3_6.0'\n",
      " 'IRFAMIN3_7.0' 'POVERTY3_2.0' 'POVERTY3_3.0' 'TROUBUND_1.0' 'MAIIN102_2.0'\n",
      " 'VESTR_40033.0' 'VESTR_40043.0' 'HLCALL_2.0' 'HLCALL_196.0']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.460127976352\n",
      "Acc: 0.941934059464\n",
      "Confusion Matrix\n",
      " [[12439   231]\n",
      " [  558   360]]\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier((100, 25), max_iter=200,tol=0, verbose=10)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = nn\n",
    "y_pred = best_model.predict(X_test)\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.03],   # Learning rate alpha\n",
    "    'max_depth': [8],   # maximum depth of the tree\n",
    "    'gamma': [0.1, 0.5],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [3, 6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [100],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=50, scoring=make_scorer(matthews_corrcoef), n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imp_feats = X_train.columns.values[grid.best_params_.get_support(indices=True)]\n",
    "# print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "xgb_model = grid.best_estimator_.fit(X_train, y_train) #[imp_feats]\n",
    "y_pred = xgb_model.predict(X_test) #[imp_feats]\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    #'num_class': 2     # num_class not required with the Binary Logistic\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "from numpy import linspace, array\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    thresholds = linspace(0.01, 0.99, 50)\n",
    "    mcc = array([matthews_corrcoef(labels, preds>thr) for thr in thresholds])\n",
    "    best_score = mcc.max()\n",
    "    return 'mcc', -best_score\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, feval = evalerror, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
