{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pandas import read_csv, DataFrame, get_dummies, Series\n",
    "from numpy import nanmean\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from boruta import BorutaPy\n",
    "import xgboost as xgb\n",
    "from random import sample\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel, SelectKBest, VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFpr, chi2, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  25095143      4.0       2.0       4.0       1.0       3.0       1.0   \n",
      "1  13005143      4.0       1.0       3.0       1.0       2.0       1.0   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY    ...     TOOLONG  TROUBUND  PDEN10  COUTYP2  \\\n",
      "0       1.0       1.0      99.0    ...         1.0       2.0     1.0      1.0   \n",
      "1       1.0       1.0      99.0    ...         2.0       2.0     2.0      3.0   \n",
      "\n",
      "   MAIIN102  AIIND102     ANALWT_C    VESTR  VEREP  Criminal  \n",
      "0       2.0       2.0  3884.805998  40026.0    1.0         0  \n",
      "1       2.0       2.0  1627.108106  40015.0    2.0         1  \n",
      "\n",
      "[2 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train data\n",
    "train = read_csv('train.csv', na_values=-1)\n",
    "print(train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['IFATHER', 'NRCH17_2', 'IRHHSIZ2', 'IIHHSIZ2', 'IRKI17_2',\n",
       "       'IIKI17_2', 'IRHH65_2', 'IIHH65_2', 'PRXRETRY', 'PRXYDATA',\n",
       "       'MEDICARE', 'CAIDCHIP', 'CHAMPUS', 'PRVHLTIN', 'GRPHLTIN',\n",
       "       'HLTINNOS', 'HLCNOTYR', 'HLCNOTMO', 'HLCLAST', 'HLLOSRSN',\n",
       "       'HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR',\n",
       "       'IRMCDCHP', 'IIMCDCHP', 'IRMEDICR', 'IIMEDICR', 'IRCHMPUS',\n",
       "       'IICHMPUS', 'IRPRVHLT', 'IIPRVHLT', 'IROTHHLT', 'IIOTHHLT',\n",
       "       'HLCALLFG', 'HLCALL99', 'ANYHLTI2', 'IRINSUR4', 'IIINSUR4',\n",
       "       'OTHINS', 'CELLNOTCL', 'CELLWRKNG', 'IRFAMSOC', 'IIFAMSOC',\n",
       "       'IRFAMSSI', 'IIFAMSSI', 'IRFSTAMP', 'IIFSTAMP', 'IRFAMPMT',\n",
       "       'IIFAMPMT', 'IRFAMSVC', 'IIFAMSVC', 'IRWELMOS', 'IIWELMOS',\n",
       "       'IRPINC3', 'IRFAMIN3', 'IIPINC3', 'IIFAMIN3', 'GOVTPROG',\n",
       "       'POVERTY3', 'TOOLONG', 'TROUBUND', 'PDEN10', 'COUTYP2', 'MAIIN102',\n",
       "       'AIIND102', 'ANALWT_C', 'VESTR', 'VEREP', 'Criminal'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop('PERID', axis=1, inplace=True)\n",
    "from numpy import inf, nan\n",
    "train = train.replace([inf, -inf], nan).dropna()\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization of Train and Test\n",
    "cols = list(X.columns.values)\n",
    "\n",
    "# Train\n",
    "X = DataFrame(normalize(X))\n",
    "X.columns = cols\n",
    "X.head(2)\n",
    "\n",
    "# Test\n",
    "test_xgb_org = DataFrame(normalize(test_xgb_org))\n",
    "test_xgb_org.columns = cols\n",
    "test_xgb_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Class\n",
      " 0    42233\n",
      "1     3060\n",
      "Name: Criminal, dtype: int64\n",
      "\n",
      "Number of unique values in each column\n",
      "\n",
      " IFATHER\n",
      "      Overall  Criminal\n",
      "4.0  0.760758  0.653922\n",
      "1.0  0.171726  0.200000\n",
      "2.0  0.067339  0.145425\n",
      "3.0  0.000177  0.000654\n",
      "\n",
      " NRCH17_2\n",
      "      Overall  Criminal\n",
      "0.0  0.731548  0.889869\n",
      "1.0  0.110370  0.051634\n",
      "2.0  0.101804  0.037582\n",
      "3.0  0.056278  0.020915\n",
      "\n",
      " IRHHSIZ2\n",
      "      Overall  Criminal\n",
      "1.0  0.078489  0.139869\n",
      "2.0  0.222639  0.267974\n",
      "3.0  0.223147  0.217320\n",
      "4.0  0.239309  0.191503\n",
      "5.0  0.136003  0.101634\n",
      "6.0  0.100413  0.081699\n",
      "\n",
      " IIHHSIZ2\n",
      "     Overall  Criminal\n",
      "1.0      1.0       1.0\n",
      "\n",
      " IRKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.417084  0.494771\n",
      "2.0  0.223015  0.191176\n",
      "3.0  0.210695  0.176797\n",
      "4.0  0.149206  0.137255\n",
      "\n",
      " IIKI17_2\n",
      "      Overall  Criminal\n",
      "1.0  0.997726  0.997712\n",
      "3.0  0.002274  0.002288\n",
      "\n",
      " IRHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.878193  0.741503\n",
      "2.0  0.079725  0.149346\n",
      "3.0  0.042082  0.109150\n",
      "\n",
      " IIHH65_2\n",
      "      Overall  Criminal\n",
      "1.0  0.995474  0.995425\n",
      "3.0  0.004018  0.004248\n",
      "2.0  0.000508  0.000327\n",
      "\n",
      " PRXRETRY\n",
      "       Overall  Criminal\n",
      "2.0   0.016603  0.014706\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000110       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.982359  0.983987\n",
      "\n",
      " PRXYDATA\n",
      "       Overall  Criminal\n",
      "1.0   0.288676  0.363399\n",
      "2.0   0.000839  0.000654\n",
      "94.0  0.000707  0.000654\n",
      "97.0  0.000066       NaN\n",
      "98.0  0.000221  0.000654\n",
      "99.0  0.709492  0.634641\n",
      "\n",
      " MEDICARE\n",
      "       Overall  Criminal\n",
      "2.0   0.912106  0.750327\n",
      "1.0   0.083567  0.236601\n",
      "94.0  0.003466  0.010131\n",
      "97.0  0.000773  0.002288\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " CAIDCHIP\n",
      "       Overall  Criminal\n",
      "1.0   0.225377  0.092484\n",
      "2.0   0.765659  0.882353\n",
      "85.0  0.001126  0.001307\n",
      "94.0  0.006911  0.020588\n",
      "97.0  0.000927  0.003268\n",
      "\n",
      " CHAMPUS\n",
      "       Overall  Criminal\n",
      "2.0   0.959817  0.962418\n",
      "1.0   0.037931  0.028105\n",
      "94.0  0.001590  0.006863\n",
      "97.0  0.000574  0.001961\n",
      "85.0  0.000088  0.000654\n",
      "\n",
      " PRVHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.607644  0.962418\n",
      "2.0   0.385932       NaN\n",
      "85.0  0.000088  0.000654\n",
      "94.0  0.005431  0.033007\n",
      "97.0  0.000905  0.003922\n",
      "\n",
      " GRPHLTIN\n",
      "       Overall  Criminal\n",
      "1.0   0.535712  0.731373\n",
      "2.0   0.070386  0.224183\n",
      "85.0  0.000066  0.000327\n",
      "94.0  0.001523  0.006536\n",
      "97.0  0.000927  0.004248\n",
      "98.0  0.005453  0.033333\n",
      "99.0  0.385932       NaN\n",
      "\n",
      " HLTINNOS\n",
      "       Overall  Criminal\n",
      "1.0   0.031175       NaN\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.000486       NaN\n",
      "97.0  0.000132       NaN\n",
      "99.0  0.866028       1.0\n",
      "\n",
      " HLCNOTYR\n",
      "       Overall  Criminal\n",
      "1.0   0.071777  0.054575\n",
      "2.0   0.815402  0.914706\n",
      "85.0  0.000464  0.000654\n",
      "94.0  0.001943  0.004902\n",
      "97.0  0.001170  0.003595\n",
      "98.0  0.007065  0.021569\n",
      "99.0  0.102179       NaN\n",
      "\n",
      " HLCLAST\n",
      "       Overall  Criminal\n",
      "1.0   0.019208       NaN\n",
      "2.0   0.012320       NaN\n",
      "3.0   0.021063       NaN\n",
      "4.0   0.028967       NaN\n",
      "5.0   0.019849       NaN\n",
      "94.0  0.000729       NaN\n",
      "97.0  0.001192  0.003268\n",
      "98.0  0.007529  0.022222\n",
      "99.0  0.889144  0.974510\n",
      "\n",
      " HLNVCOST\n",
      "       Overall  Criminal\n",
      "1.0   0.009913       NaN\n",
      "6.0   0.009869       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVOFFR\n",
      "       Overall  Criminal\n",
      "1.0   0.002914       NaN\n",
      "6.0   0.016868       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVREF\n",
      "       Overall  Criminal\n",
      "1.0   0.000596       NaN\n",
      "6.0   0.019186       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVNEED\n",
      "       Overall  Criminal\n",
      "1.0   0.003974       NaN\n",
      "6.0   0.015808       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " HLNVSOR\n",
      "       Overall  Criminal\n",
      "1.0   0.002936       NaN\n",
      "6.0   0.016846       NaN\n",
      "94.0  0.000066       NaN\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.007750  0.022222\n",
      "99.0  0.971254  0.974510\n",
      "\n",
      " IRMCDCHP\n",
      "     Overall  Criminal\n",
      "2.0  0.77151  0.895425\n",
      "1.0  0.22849  0.104575\n",
      "\n",
      " IIMCDCHP\n",
      "      Overall  Criminal\n",
      "1.0  0.991036  0.974837\n",
      "3.0  0.008964  0.025163\n",
      "\n",
      " IRMEDICR\n",
      "      Overall  Criminal\n",
      "2.0  0.916256  0.762745\n",
      "1.0  0.083744  0.237255\n",
      "\n",
      " IIMEDICR\n",
      "      Overall  Criminal\n",
      "1.0  0.995673  0.986928\n",
      "3.0  0.004327  0.013072\n",
      "\n",
      " IRCHMPUS\n",
      "      Overall  Criminal\n",
      "2.0  0.962025  0.971895\n",
      "1.0  0.037975  0.028105\n",
      "\n",
      " IICHMPUS\n",
      "      Overall  Criminal\n",
      "1.0  0.997748  0.990523\n",
      "3.0  0.002252  0.009477\n",
      "\n",
      " IRPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.611044  0.977778\n",
      "2.0  0.388956  0.022222\n",
      "\n",
      " IIPRVHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.993575  0.962418\n",
      "3.0  0.006425  0.037582\n",
      "\n",
      " IROTHHLT\n",
      "       Overall  Criminal\n",
      "99.0  0.863489  0.994444\n",
      "2.0   0.104564  0.004575\n",
      "1.0   0.031948  0.000980\n",
      "\n",
      " IIOTHHLT\n",
      "      Overall  Criminal\n",
      "1.0  0.133354       NaN\n",
      "3.0  0.008677   0.02549\n",
      "9.0  0.857969   0.97451\n",
      "\n",
      " HLCALLFG\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " HLCALL99\n",
      "       Overall  Criminal\n",
      "98.0  0.999801  0.997712\n",
      "1.0   0.000199  0.002288\n",
      "\n",
      " ANYHLTI2\n",
      "       Overall  Criminal\n",
      "1.0   0.889144  0.974510\n",
      "2.0   0.102179       NaN\n",
      "94.0  0.007043  0.021569\n",
      "97.0  0.001148  0.003268\n",
      "98.0  0.000486  0.000654\n",
      "\n",
      " IRINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.895436  0.995425\n",
      "2.0  0.104564  0.004575\n",
      "\n",
      " IIINSUR4\n",
      "      Overall  Criminal\n",
      "1.0  0.991323   0.97451\n",
      "3.0  0.008677   0.02549\n",
      "\n",
      " OTHINS\n",
      "     Overall  Criminal\n",
      "2.0   0.8549  0.749673\n",
      "1.0   0.1451  0.250327\n",
      "\n",
      " CELLNOTCL\n",
      "       Overall  Criminal\n",
      "1.0   0.433312  0.477451\n",
      "2.0   0.565385  0.520588\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000442  0.000327\n",
      "97.0  0.000640  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " CELLWRKNG\n",
      "       Overall  Criminal\n",
      "1.0   0.977016  0.952614\n",
      "2.0   0.022255  0.045425\n",
      "85.0  0.000110  0.000654\n",
      "94.0  0.000110  0.000327\n",
      "97.0  0.000397  0.000980\n",
      "98.0  0.000110       NaN\n",
      "\n",
      " IRFAMSOC\n",
      "      Overall  Criminal\n",
      "2.0  0.836796  0.677778\n",
      "1.0  0.163204  0.322222\n",
      "\n",
      " IIFAMSOC\n",
      "      Overall  Criminal\n",
      "1.0  0.991213  0.982026\n",
      "3.0  0.008787  0.017974\n",
      "\n",
      " IRFAMSSI\n",
      "      Overall  Criminal\n",
      "2.0  0.931446  0.926471\n",
      "1.0  0.068554  0.073529\n",
      "\n",
      " IIFAMSSI\n",
      "      Overall  Criminal\n",
      "1.0  0.991058  0.977778\n",
      "3.0  0.008942  0.022222\n",
      "\n",
      " IRFSTAMP\n",
      "      Overall  Criminal\n",
      "2.0  0.798931  0.807516\n",
      "1.0  0.201069  0.192484\n",
      "\n",
      " IIFSTAMP\n",
      "      Overall  Criminal\n",
      "1.0  0.995584  0.989869\n",
      "3.0  0.004416  0.010131\n",
      "\n",
      " IRFAMPMT\n",
      "      Overall  Criminal\n",
      "2.0  0.973197  0.975163\n",
      "1.0  0.026803  0.024837\n",
      "\n",
      " IIFAMPMT\n",
      "      Overall  Criminal\n",
      "1.0  0.993134   0.98268\n",
      "3.0  0.006866   0.01732\n",
      "\n",
      " IRFAMSVC\n",
      "      Overall  Criminal\n",
      "2.0  0.963858  0.962418\n",
      "1.0  0.036142  0.037582\n",
      "\n",
      " IIFAMSVC\n",
      "      Overall  Criminal\n",
      "1.0  0.994922  0.985621\n",
      "3.0  0.005078  0.014379\n",
      "\n",
      " IIWELMOS\n",
      "      Overall  Criminal\n",
      "9.0  0.938379  0.927124\n",
      "1.0  0.052149  0.050000\n",
      "3.0  0.009472  0.022876\n",
      "\n",
      " IRPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.468549  0.632026\n",
      "2.0  0.157132  0.181046\n",
      "3.0  0.099773  0.102941\n",
      "4.0  0.072506  0.053922\n",
      "5.0  0.058817  0.030065\n",
      "6.0  0.073102       NaN\n",
      "7.0  0.070121       NaN\n",
      "\n",
      " IRFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.082551  0.128431\n",
      "2.0  0.122248  0.166013\n",
      "3.0  0.110790  0.211765\n",
      "4.0  0.105248  0.240523\n",
      "5.0  0.099508  0.253268\n",
      "6.0  0.157022       NaN\n",
      "7.0  0.322633       NaN\n",
      "\n",
      " IIPINC3\n",
      "      Overall  Criminal\n",
      "1.0  0.969907  0.950654\n",
      "3.0  0.030093  0.049346\n",
      "\n",
      " IIFAMIN3\n",
      "      Overall  Criminal\n",
      "1.0  0.903385  0.860458\n",
      "3.0  0.096615  0.139542\n",
      "\n",
      " GOVTPROG\n",
      "      Overall  Criminal\n",
      "2.0  0.761332  0.757843\n",
      "1.0  0.238668  0.242157\n",
      "\n",
      " POVERTY3\n",
      "      Overall  Criminal\n",
      "1.0  0.205551   0.27451\n",
      "2.0  0.225289   0.47451\n",
      "3.0  0.569161   0.25098\n",
      "\n",
      " TOOLONG\n",
      "       Overall  Criminal\n",
      "2.0   0.924779  0.899673\n",
      "1.0   0.072594  0.097059\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " TROUBUND\n",
      "       Overall  Criminal\n",
      "2.0   0.940388  0.917320\n",
      "1.0   0.056985  0.079412\n",
      "98.0  0.002627  0.003268\n",
      "\n",
      " PDEN10\n",
      "      Overall  Criminal\n",
      "2.0  0.490584  0.538889\n",
      "1.0  0.432142  0.369608\n",
      "3.0  0.077275  0.091503\n",
      "\n",
      " COUTYP2\n",
      "      Overall  Criminal\n",
      "1.0  0.443976  0.383987\n",
      "2.0  0.348509  0.375817\n",
      "3.0  0.207516  0.240196\n",
      "\n",
      " MAIIN102\n",
      "      Overall  Criminal\n",
      "2.0  0.978915  0.979739\n",
      "1.0  0.021085  0.020261\n",
      "\n",
      " AIIND102\n",
      "      Overall  Criminal\n",
      "2.0  0.978716  0.979085\n",
      "1.0  0.021284  0.020915\n",
      "\n",
      " VEREP\n",
      "      Overall  Criminal\n",
      "1.0  0.506414  0.519608\n",
      "2.0  0.493586  0.480392\n",
      "\n",
      " Criminal\n",
      "   Overall  Criminal\n",
      "0  0.93244       NaN\n",
      "1  0.06756       1.0\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance\n",
    "print('Target Class\\n', train['Criminal'].value_counts())\n",
    "cols = train.columns.values\n",
    "\n",
    "# Number of unique values\n",
    "print('\\nNumber of unique values in each column')\n",
    "overall = train.shape[0]\n",
    "train_criminal = train[train['Criminal']==1]\n",
    "criminal = train_criminal.shape[0]\n",
    "for col in cols:\n",
    "    if len(train[col].unique()) > 10:\n",
    "        continue\n",
    "    print('\\n', col)\n",
    "    temp = DataFrame({'Overall': train[col].value_counts() / overall,\n",
    "                      'Criminal': train_criminal[col].value_counts() / criminal})\n",
    "    print(temp[['Overall', 'Criminal']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating \"NC17\" column by removing (NRCH17_2, IRHHSIZ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['NC17'] = train['NRCH17_2'] / train['IRHHSIZ2']\n",
    "del train['NRCH17_2']\n",
    "del train['IRHHSIZ2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining \"HLNV\" columns   and   \"HLCALL\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n"
     ]
    }
   ],
   "source": [
    "hlnv_cols = [col for col in train.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "train['HLNV'] = train[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in train.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "train['HLCALL'] = train[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "train = train.drop(hlcall_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming \"HLCNOTMO\"  and  \"HLCLAST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['HLCNOTMO'] = train['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "train['HLCLAST'] = train['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "target = ['Criminal']\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in train.columns.values if col not in (num_cols + target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 5 59\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns.values), len(num_cols), len(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding and Frequency based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n"
     ]
    }
   ],
   "source": [
    "# Converting to categorical and one hot encoding\n",
    "freqs = {}\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    # Get counts, sums and frequency of is_attributed\n",
    "    df = DataFrame({\n",
    "        'sums': train.groupby(col)['Criminal'].sum(),\n",
    "        'counts': train.groupby(col)['Criminal'].count()\n",
    "    })\n",
    "    df.loc[:, 'freq'] = df.sums / df.counts\n",
    "    \n",
    "    # If we have less than 3 observations, e.g. for an IP, then assume freq of 0\n",
    "    df.loc[df.counts <= 3, 'freq'] = 0      \n",
    "    \n",
    "    # Saving in dictionary\n",
    "    freqs[col] = df\n",
    "    \n",
    "    # Add to X_total\n",
    "    train[col+'_freq'] = train[col].map(df['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    #train[col] = train[col].astype('category',copy=False)\n",
    "    temp = get_dummies(train[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    train = train.join(temp)\n",
    "    train = train.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IRKI17_2</th>\n",
       "      <th>IRHH65_2</th>\n",
       "      <th>IRWELMOS</th>\n",
       "      <th>ANALWT_C</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>NC17</th>\n",
       "      <th>IFATHER_freq</th>\n",
       "      <th>IFATHER_1</th>\n",
       "      <th>IFATHER_2</th>\n",
       "      <th>IFATHER_3</th>\n",
       "      <th>...</th>\n",
       "      <th>HLNV_15</th>\n",
       "      <th>HLNV_20</th>\n",
       "      <th>HLNV_25</th>\n",
       "      <th>HLNV_470</th>\n",
       "      <th>HLNV_485</th>\n",
       "      <th>HLNV_490</th>\n",
       "      <th>HLNV_495</th>\n",
       "      <th>HLCALL_freq</th>\n",
       "      <th>HLCALL_2</th>\n",
       "      <th>HLCALL_196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3884.805998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1627.108106</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.058072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IRKI17_2  IRHH65_2  IRWELMOS     ANALWT_C  Criminal      NC17  \\\n",
       "0       3.0       1.0      99.0  3884.805998         0  0.500000   \n",
       "1       2.0       1.0      99.0  1627.108106         1  0.333333   \n",
       "\n",
       "   IFATHER_freq  IFATHER_1  IFATHER_2  IFATHER_3     ...      HLNV_15  \\\n",
       "0      0.058072          0          0          0     ...            0   \n",
       "1      0.058072          0          0          0     ...            0   \n",
       "\n",
       "   HLNV_20  HLNV_25  HLNV_470  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  \\\n",
       "0        0        0         0         0         0         1     0.067419   \n",
       "1        0        0         0         0         0         1     0.067419   \n",
       "\n",
       "   HLCALL_2  HLCALL_196  \n",
       "0         0           1  \n",
       "1         0           1  \n",
       "\n",
       "[2 rows x 314 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing value check\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outliers\n",
    "fig, ax = plt.subplots(figsize=(15,  15))\n",
    "# X_train.boxplot(by='target', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bar plots\n",
    "train.iloc[:, :4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding best distribution for each feature\n",
    "\n",
    "cdfs = [\n",
    "    \"norm\",            #Normal (Gaussian)\n",
    "    \"alpha\",           #Alpha\n",
    "    \"beta\",            #Beta\n",
    "    \"expon\",           #Exponential\n",
    "    \"gamma\",           #Gamma\n",
    "    \"laplace\",         #Laplace\n",
    "    \"rayleigh\",        #Rayleigh\n",
    "    \"uniform\",         #Uniform\n",
    "       ]\n",
    "\n",
    "col_name=list(X_train.columns.values)\n",
    "X_train.fillna(0, inplace=True)\n",
    "trans = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    p_max = -100\n",
    "    dist = ''\n",
    "    temp = X_train[col_name[i]].transpose().values.tolist()\n",
    "    # fit our data set against every probability distribution\n",
    "    for cdf in cdfs:\n",
    "        parameters = eval(\"stats.\"+cdf+\".fit(temp)\")\n",
    "        #Applying the Kolmogorov-Smirnof one sided test\n",
    "        D, p = stats.kstest(temp, cdf, args=parameters)\n",
    "        if p > p_max:\n",
    "            p_max = p\n",
    "            dist = cdf\n",
    "            #pretty-print the results\n",
    "        #print cdf.ljust(16) + (\"p: \"+str(p)).ljust(25)+\"D: \"+str(D)\n",
    "    #trans.append(dist)\n",
    "    trans[col_name[i]]=dist\n",
    "    print(col_name[i], \":\", dist, \"distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering / Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking collinearity (using correlation)\n",
    "correl = train.corr()\n",
    "# train[\"feat_1\"].corr(train[\"feat_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = train.columns.values\n",
    "for i in range(len(cols)):\n",
    "    for j in range(i+1, len(cols)):\n",
    "        curr_cor = correl.loc[cols[i], cols[j]]\n",
    "        if (curr_cor >= 0.9) and (curr_cor < 1):\n",
    "            print(cols[i], cols[j], curr_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance Threshold Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vt = VarianceThreshold()\n",
    "vt_train = vt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vt.variances_\n",
    "vt_df = DataFrame({'feature': list(train.columns.values), 'variance': vt.variances_}).sort_values(by='variance', ascending=True)\n",
    "print(vt_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train['Criminal']\n",
    "X = train[[col for col in train.columns.values if col not in ['PERID', 'Criminal']]]\n",
    "# X['download_time'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing Multicollinearity (using VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "from numpy import arange, delete\n",
    "\n",
    "def calculate_vif(X, thresh=100):\n",
    "    cols = X.columns\n",
    "    variables = arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = calculate_vif(X, 10)\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45247, 313) (46, 313)\n"
     ]
    }
   ],
   "source": [
    "# Splitting Train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.001, random_state=45)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing data\n",
    "norm_train = DataFrame(normalize(X_train))\n",
    "norm_train.columns = list(X_train.columns.values)\n",
    "norm_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = norm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=len(X_train.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train = DataFrame(pca.fit_transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(pca.explained_variance_[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = Series(rf.feature_importances_, index=X_train.columns.values).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4IAAAIlCAYAAACAZ0aDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\na7IOoTUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28588df46d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp[:30].plot(kind='bar', title='Feature Importance with Random Forest', figsize=(15,8))\n",
    "plt.ylabel('Feature Importance values')\n",
    "#plt.subplots_adjust(bottom=0.25)\n",
    "#plt.savefig('FeatImportance.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IRFAMIN3_freq', 'ANALWT_C', 'VESTR_freq', 'POVERTY3_freq', 'IRPINC3_freq', 'POVERTY3_3', 'IRPINC3_1', 'IRFAMIN3_7', 'GRPHLTIN_freq', 'IRFAMIN3_6', 'IFATHER_freq', 'IRFAMIN3_5', 'IFATHER_4', 'POVERTY3_2', 'IRKI17_2', 'IRFAMIN3_4', 'GRPHLTIN_99', 'PRVHLTIN_freq', 'PRVHLTIN_2', 'IRPRVHLT_freq', 'POVERTY3_1', 'IRPRVHLT_2', 'NC17', 'IRPRVHLT_1', 'COUTYP2_freq', 'PRXYDATA_1', 'IRFAMIN3_3', 'GRPHLTIN_1', 'PRXYDATA_99', 'PRVHLTIN_1', 'PRXYDATA_freq', 'VEREP_1', 'VEREP_2', 'VEREP_freq', 'PDEN10_freq', 'GRPHLTIN_2', 'IRHH65_2', 'COUTYP2_2', 'IFATHER_2', 'CELLNOTCL_1', 'CELLNOTCL_freq', 'CELLNOTCL_2', 'IFATHER_1', 'PDEN10_2', 'MEDICARE_2', 'COUTYP2_3', 'MEDICARE_freq', 'IRFAMSOC_1', 'IRFAMIN3_2', 'IRPINC3_2', 'IRFAMSOC_2', 'MEDICARE_1', 'IRMEDICR_2', 'COUTYP2_1', 'IRPINC3_3', 'PDEN10_1', 'IRFAMSOC_freq', 'IRMEDICR_freq', 'IRMEDICR_1', 'IRFAMIN3_1', 'IIFAMIN3_freq', 'TOOLONG_freq', 'IIFAMIN3_3', 'IIFAMIN3_1', 'TOOLONG_1', 'TOOLONG_2', 'VESTR_40049', 'IRFSTAMP_freq', 'IRFSTAMP_2', 'GOVTPROG_freq', 'GOVTPROG_2', 'IRFSTAMP_1', 'GOVTPROG_1', 'OTHINS_freq', 'OTHINS_1', 'CAIDCHIP_freq', 'PDEN10_3', 'TROUBUND_freq', 'OTHINS_2', 'TROUBUND_2', 'TROUBUND_1', 'IRMCDCHP_2', 'IRPINC3_4', 'IRMCDCHP_1', 'VESTR_40023', 'VESTR_40043', 'VESTR_40038', 'VESTR_40010', 'CAIDCHIP_1', 'VESTR_40021', 'VESTR_40028', 'VESTR_40029', 'VESTR_40041', 'CAIDCHIP_2', 'HLCNOTYR_freq', 'VESTR_40039', 'IRMCDCHP_freq', 'VESTR_40048', 'VESTR_40018', 'VESTR_40040', 'VESTR_40005', 'VESTR_40045', 'VESTR_40022', 'VESTR_40035', 'VESTR_40025', 'VESTR_40046', 'VESTR_40019', 'VESTR_40024', 'VESTR_40007', 'VESTR_40012', 'VESTR_40013', 'VESTR_40001', 'VESTR_40009', 'VESTR_40003', 'VESTR_40004', 'VESTR_40026', 'VESTR_40020', 'IRFAMSSI_2', 'IRFAMSSI_1', 'VESTR_40014', 'VESTR_40011', 'VESTR_40047', 'IRFAMSSI_freq', 'VESTR_40017', 'VESTR_40034', 'VESTR_40044', 'VESTR_40036', 'IRWELMOS', 'VESTR_40008', 'CELLWRKNG_freq', 'VESTR_40033', 'HLCNOTYR_1', 'CELLWRKNG_2', 'VESTR_40027', 'HLCNOTYR_2', 'CELLWRKNG_1', 'VESTR_40016', 'VESTR_40031', 'VESTR_40032', 'HLCNOTMO_1', 'HLCNOTMO_0', 'HLCNOTMO_freq', 'VESTR_40015', 'VESTR_40042', 'VESTR_40002', 'IRPINC3_5', 'VESTR_40006', 'IIPINC3_freq', 'IIPINC3_3', 'IIPINC3_1', 'VESTR_40030', 'VESTR_40037', 'VESTR_40050', 'IIWELMOS_freq', 'IRPINC3_6', 'IIWELMOS_9', 'IIPRVHLT_freq', 'IIPRVHLT_1', 'IIPRVHLT_3', 'GRPHLTIN_98', 'PRVHLTIN_94', 'IIWELMOS_1', 'IRPINC3_7', 'CHAMPUS_freq', 'IRFAMSVC_1', 'IRFAMSVC_freq', 'IRFAMSVC_2', 'PRXRETRY_freq', 'PRXRETRY_2', 'PRXRETRY_99', 'CHAMPUS_2', 'IRCHMPUS_freq', 'IRFAMPMT_2', 'IRFAMPMT_1', 'IRFAMPMT_freq', 'IRCHMPUS_1', 'IRCHMPUS_2', 'CHAMPUS_1', 'AIIND102_1', 'AIIND102_freq', 'AIIND102_2', 'MAIIN102_2', 'GRPHLTIN_94', 'MAIIN102_1', 'MAIIN102_freq', 'IIFAMSSI_freq', 'IIFAMSSI_3', 'IIFAMSSI_1', 'IIOTHHLT_freq', 'IROTHHLT_freq', 'IIOTHHLT_1', 'HLTINNOS_99', 'ANYHLTI2_freq', 'IIFAMSOC_1', 'HLTINNOS_freq', 'IIWELMOS_3', 'IIFAMSOC_freq', 'IIOTHHLT_9', 'IIMCDCHP_3', 'IIFAMSOC_3', 'IIMCDCHP_freq', 'IIMCDCHP_1', 'CAIDCHIP_94', 'IROTHHLT_99', 'IIHH65_2_freq', 'IIFAMPMT_1', 'IIFAMPMT_freq', 'IIFAMPMT_3', 'IIHH65_2_1', 'HLCLAST_freq', 'IIHH65_2_3', 'IIFAMSVC_freq', 'IIFAMSVC_3', 'IIFAMSVC_1', 'IIKI17_2_1', 'IIKI17_2_freq', 'IIKI17_2_3', 'HLTINNOS_2', 'IIFSTAMP_1', 'HLLOSRSN_freq', 'HLCNOTYR_94', 'IIFSTAMP_freq', 'IIFSTAMP_3', 'TOOLONG_98', 'HLLOSRSN_99', 'HLNV_freq', 'ANYHLTI2_1', 'ANYHLTI2_2', 'HLCLAST_1', 'HLCNOTYR_99', 'IRINSUR4_1', 'TROUBUND_98', 'IROTHHLT_2', 'HLCLAST_0', 'IIINSUR4_1', 'IIINSUR4_freq', 'IIMEDICR_1', 'HLCNOTYR_98', 'IIMEDICR_freq', 'MEDICARE_94', 'IIINSUR4_3', 'HLLOSRSN_98', 'IICHMPUS_1', 'ANYHLTI2_94', 'IIMEDICR_3', 'HLNV_490', 'IICHMPUS_freq', 'IIOTHHLT_3', 'IRINSUR4_freq', 'HLNV_495', 'IICHMPUS_3', 'IRINSUR4_2', 'CELLWRKNG_94', 'CHAMPUS_94', 'GRPHLTIN_97', 'HLCALL_2', 'HLCALL_196', 'HLCALL_freq', 'CELLNOTCL_94', 'PRVHLTIN_97', 'IROTHHLT_1', 'IIHH65_2_2', 'PRXYDATA_94', 'PRXYDATA_2', 'CAIDCHIP_97', 'IFATHER_3', 'PRXRETRY_94', 'HLCNOTYR_97', 'CAIDCHIP_85', 'ANYHLTI2_97', 'HLNV_485', 'HLLOSRSN_97', 'CHAMPUS_97', 'HLTINNOS_1', 'CELLNOTCL_97', 'MEDICARE_97', 'CELLWRKNG_97', 'PRXYDATA_98', 'GRPHLTIN_85', 'MEDICARE_85']\n"
     ]
    }
   ],
   "source": [
    "imp_feats = list(feat_imp[:280].index)\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X[imp_feats]\n",
    "X_train = X_train[imp_feats]\n",
    "X_test = X_test[imp_feats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select From Model\n",
    "feats = list(X_train.columns.values)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, verbose=2, random_state=1, max_depth=20)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = SelectFromModel(rf)\n",
    "\n",
    "# find all relevant features - 20 features should be selected\n",
    "feat_selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sfmodel_feats = [feats[i] for i in feat_selector.get_support(indices=True)]\n",
    "print(sfmodel_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline (AdaBoost, RF, SVM, ET, KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline_params():\n",
    "    rf = RandomForestClassifier()\n",
    "    et = ExtraTreesClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    xg = xgb.XGBClassifier()\n",
    "    gb = GradientBoostingClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    rfe = RFE(rf, step=0.2)\n",
    "    select = SelectFromModel(rf)\n",
    "    kbest = SelectKBest(chi2)\n",
    "    pipe = Pipeline([('feat_sel', rfe), ('model', rf)])\n",
    "    feat_sel_params = [\n",
    "        {\n",
    "            'feat_sel': [kbest],\n",
    "            'feat_sel__k': [30]},\n",
    "        {\n",
    "            'feat_sel': [rfe],\n",
    "            'feat_sel__estimator': [rf], #rf, et, gb, xg\n",
    "            'feat_sel__n_features_to_select': [30]},\n",
    "        {\n",
    "            'feat_sel': [select],\n",
    "            'feat_sel__estimator': [rf]} #rf, et, gb, xg\n",
    "    ]\n",
    "    model_params = [\n",
    "        {\n",
    "            'model': [lr]},\n",
    "        {\n",
    "            'model': [gb],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__learning_rate': [0.03]}, #0.01, 0.04, 0.1, 0.5, 1\n",
    "        {\n",
    "            'model': [ada],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__learning_rate': [0.03], #0.01, 0.04, 0.1, 0.5, 1\n",
    "            'model__random_state': [9]},\n",
    "        {\n",
    "            'model': [xg],\n",
    "            'model__objective': ['binary:logistic'],\n",
    "            'model__learning_rate': [0.03],   # Learning rate alpha\n",
    "            'model__gamma': [0.1],   # minimum eval_score deduction at each split\n",
    "            'model__min_child_weight': [4],  # minimum number of datapoints in a split\n",
    "            'model__subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "            'model__colsample_bytree': [0.7],  # column-wise sample size\n",
    "            'model__n_estimators': [100]},   # number of trees to build\n",
    "        {\n",
    "            'model': [rf],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7, 9\n",
    "            'model__max_depth': [11]}, #8, 10, 14\n",
    "        {\n",
    "            'model': [et],\n",
    "            'model__n_estimators': [100], #500, 1000, 2000, 4000\n",
    "            'model__criterion': ['gini', 'entropy'],\n",
    "            'model__max_features': ['sqrt'], #, 'log2'\n",
    "            'model__min_samples_leaf': [4], #3, 5, 7\n",
    "            'model__max_depth': [11]} #8, 10, 14\n",
    "    ]\n",
    "    params = []\n",
    "    for feat_sel in feat_sel_params:\n",
    "        for model in model_params:\n",
    "            # Merge dictionaries and append to list\n",
    "            params.append({**feat_sel, **model})\n",
    "    return pipe, feat_sel_params, model_params, params\n",
    "\n",
    "pipe, feat_params, model_params, all_params = pipeline_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=pipe, param_grid=all_params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV results\n",
    "cv_result_pipe = DataFrame(grid.cv_results_).sort_values('rank_test_score').to_csv('cv_result_pipe.csv', index=False)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_feats = X_train.columns.values[grid.best_params_['feat_sel'].get_support(indices=True)]\n",
    "print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_.fit(X_train[imp_feats], y_train)\n",
    "y_pred = best_model.predict(X_test[imp_feats])\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_model_combo():\n",
    "    rfe_rf = RFE(RandomForestClassifier(n_estimators=100), step=0.2, n_features_to_select=30)\n",
    "    select_rf = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "    rfe_et = RFE(ExtraTreesClassifier(n_estimators=100), step=0.2, n_features_to_select=30)\n",
    "    select_et = SelectFromModel(ExtraTreesClassifier(n_estimators=100))\n",
    "\n",
    "    rf_gini = RandomForestClassifier(n_estimators=1000, criterion='gini', max_depth=11, max_features='sqrt',\n",
    "                                     min_samples_leaf=4, n_jobs=-1)\n",
    "    rf_ent = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=11, max_features='sqrt',\n",
    "                                    min_samples_leaf=4, n_jobs=-1)\n",
    "\n",
    "    et_gini = ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=11, max_features='sqrt',\n",
    "                                   min_samples_leaf=4, n_jobs=-1)\n",
    "    et_ent = ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=11, max_features='sqrt',\n",
    "                                  min_samples_leaf=4, n_jobs=-1)\n",
    "\n",
    "    xg = xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)\n",
    "\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    combo = [\n",
    "        # RFE (rf + et + xgb)\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                     min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': rfe_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        # SelectFrom Model  (rf + et + xgb)\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='gini', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=3, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=5, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': ExtraTreesClassifier(n_estimators=1000, criterion='entropy', max_depth=14, max_features='sqrt',\n",
    "                                         min_samples_leaf=7, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_rf,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.5, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.5,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)},\n",
    "        {'feat_sel': select_et,\n",
    "         'model': xgb.XGBClassifier(n_estimators=1000, objective='binary:logistic', colsample_bytree=0.7, gamma=0.2,\n",
    "                                    learning_rate=0.2, min_child_weight=5, subsample=0.9, n_jobs=-1)}\n",
    "    ]\n",
    "    return combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_mixed(combo, X_train, y_train, X_test, y_test, prob=False):\n",
    "    preds = DataFrame()\n",
    "    preds['y_true'] = y # Check for y and y_test\n",
    "    trained_models = {}\n",
    "    features = X_train.columns.values\n",
    "    \n",
    "    for i, one in zip(range(1, len(combo)+1), combo):\n",
    "        print('\\n')\n",
    "        trained_models[i] = {}\n",
    "        \n",
    "        feat_sel = one['feat_sel']\n",
    "        feat_sel.fit(X_train, y_train)\n",
    "        \n",
    "        imp_feat = [features[i] for i in feat_sel.get_support(indices=True)]\n",
    "        if len(imp_feat)>30:\n",
    "            imp_feat = imp_feat[:30]\n",
    "        print(len(imp_feat))\n",
    "        trained_models[i]['feats'] = imp_feat\n",
    "        \n",
    "        model = one['model']\n",
    "        model.fit(X_train[imp_feat], y_train)\n",
    "        trained_models[i]['model'] = model\n",
    "        \n",
    "        # print(feat_sel, model)\n",
    "        \n",
    "        if prob:\n",
    "            pred = model.predict_proba(X[imp_feat]) # Check for X and X_test   \n",
    "            # preds[key+'_0'] = [i[0] for i in pred]\n",
    "            preds['pred'+str(i)] = [j[1] for j in pred]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            preds['pred'+str(i)] = model.predict(X[imp_feat]) # Check for X and X_test       \n",
    "            print('MCC:', matthews_corrcoef(preds['y_true'], preds['pred'+str(i)]))\n",
    "            print('Acc:', accuracy_score(preds['y_true'], preds['pred'+str(i)]))\n",
    "            print('Confusion Matrix\\n', confusion_matrix(preds['y_true'], preds['pred'+str(i)]))\n",
    "    \n",
    "    if prob:\n",
    "        preds.to_excel('mixed_ensemble_proba.xlsx', index=False)\n",
    "    else:\n",
    "        preds.to_excel('mixed_ensemble_preds.xlsx', index=False)\n",
    "    \n",
    "    return preds, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "30\n",
      "MCC: 0.676652442207\n",
      "Acc: 0.961936723114\n",
      "Confusion Matrix\n",
      " [[41615   618]\n",
      " [ 1106  1954]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.654187976978\n",
      "Acc: 0.959243150156\n",
      "Confusion Matrix\n",
      " [[41546   687]\n",
      " [ 1159  1901]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.643199859894\n",
      "Acc: 0.957830128276\n",
      "Confusion Matrix\n",
      " [[41502   731]\n",
      " [ 1179  1881]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.668566532217\n",
      "Acc: 0.960943192105\n",
      "Confusion Matrix\n",
      " [[41587   646]\n",
      " [ 1123  1937]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.651809114522\n",
      "Acc: 0.958934051619\n",
      "Confusion Matrix\n",
      " [[41536   697]\n",
      " [ 1163  1897]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.644756458793\n",
      "Acc: 0.958072991411\n",
      "Confusion Matrix\n",
      " [[41513   720]\n",
      " [ 1179  1881]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.671748984196\n",
      "Acc: 0.961318526042\n",
      "Confusion Matrix\n",
      " [[41596   637]\n",
      " [ 1115  1945]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.657130668045\n",
      "Acc: 0.959596405626\n",
      "Confusion Matrix\n",
      " [[41555   678]\n",
      " [ 1152  1908]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.64390579381\n",
      "Acc: 0.957984677544\n",
      "Confusion Matrix\n",
      " [[41512   721]\n",
      " [ 1182  1878]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.67586490889\n",
      "Acc: 0.96189256618\n",
      "Confusion Matrix\n",
      " [[41619   614]\n",
      " [ 1112  1948]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.653924910112\n",
      "Acc: 0.95935354249\n",
      "Confusion Matrix\n",
      " [[41562   671]\n",
      " [ 1170  1890]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.645560920925\n",
      "Acc: 0.958183383746\n",
      "Confusion Matrix\n",
      " [[41517   716]\n",
      " [ 1178  1882]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.733856003618\n",
      "Acc: 0.968118693838\n",
      "Confusion Matrix\n",
      " [[41693   540]\n",
      " [  904  2156]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.730362069282\n",
      "Acc: 0.967787516835\n",
      "Confusion Matrix\n",
      " [[41696   537]\n",
      " [  922  2138]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.742958112418\n",
      "Acc: 0.969112224847\n",
      "Confusion Matrix\n",
      " [[41704   529]\n",
      " [  870  2190]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.744962947137\n",
      "Acc: 0.969355087983\n",
      "Confusion Matrix\n",
      " [[41710   523]\n",
      " [  865  2195]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.721767968104\n",
      "Acc: 0.966749828892\n",
      "Confusion Matrix\n",
      " [[41670   563]\n",
      " [  943  2117]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.716500471112\n",
      "Acc: 0.96619786722\n",
      "Confusion Matrix\n",
      " [[41666   567]\n",
      " [  964  2096]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.73235106638\n",
      "Acc: 0.967919987636\n",
      "Confusion Matrix\n",
      " [[41686   547]\n",
      " [  906  2154]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.736770305851\n",
      "Acc: 0.968538184708\n",
      "Confusion Matrix\n",
      " [[41712   521]\n",
      " [  904  2156]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.627663887795\n",
      "Acc: 0.958492482282\n",
      "Confusion Matrix\n",
      " [[41761   472]\n",
      " [ 1408  1652]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.600689287227\n",
      "Acc: 0.955953458592\n",
      "Confusion Matrix\n",
      " [[41738   495]\n",
      " [ 1500  1560]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.580572857296\n",
      "Acc: 0.954098867375\n",
      "Confusion Matrix\n",
      " [[41721   512]\n",
      " [ 1567  1493]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.622629549842\n",
      "Acc: 0.958072991411\n",
      "Confusion Matrix\n",
      " [[41765   468]\n",
      " [ 1431  1629]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.595783842586\n",
      "Acc: 0.955445653854\n",
      "Confusion Matrix\n",
      " [[41727   506]\n",
      " [ 1512  1548]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.579377653769\n",
      "Acc: 0.954076788908\n",
      "Confusion Matrix\n",
      " [[41731   502]\n",
      " [ 1578  1482]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.630394093821\n",
      "Acc: 0.958757423884\n",
      "Confusion Matrix\n",
      " [[41764   469]\n",
      " [ 1399  1661]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.598998590596\n",
      "Acc: 0.955776830857\n",
      "Confusion Matrix\n",
      " [[41734   499]\n",
      " [ 1504  1556]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.582953972913\n",
      "Acc: 0.954363808977\n",
      "Confusion Matrix\n",
      " [[41729   504]\n",
      " [ 1563  1497]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.625175887594\n",
      "Acc: 0.958249619146\n",
      "Confusion Matrix\n",
      " [[41758   475]\n",
      " [ 1416  1644]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.596786155933\n",
      "Acc: 0.955578124655\n",
      "Confusion Matrix\n",
      " [[41733   500]\n",
      " [ 1512  1548]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.579937491747\n",
      "Acc: 0.954076788908\n",
      "Confusion Matrix\n",
      " [[41725   508]\n",
      " [ 1572  1488]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.676116085272\n",
      "Acc: 0.962576998653\n",
      "Confusion Matrix\n",
      " [[41708   525]\n",
      " [ 1170  1890]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.680018325292\n",
      "Acc: 0.962996489524\n",
      "Confusion Matrix\n",
      " [[41715   518]\n",
      " [ 1158  1902]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.698743764798\n",
      "Acc: 0.965027708476\n",
      "Confusion Matrix\n",
      " [[41750   483]\n",
      " [ 1101  1959]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.695535687047\n",
      "Acc: 0.964652374539\n",
      "Confusion Matrix\n",
      " [[41740   493]\n",
      " [ 1108  1952]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.676116085272\n",
      "Acc: 0.962576998653\n",
      "Confusion Matrix\n",
      " [[41708   525]\n",
      " [ 1170  1890]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.680018325292\n",
      "Acc: 0.962996489524\n",
      "Confusion Matrix\n",
      " [[41715   518]\n",
      " [ 1158  1902]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.695330766497\n",
      "Acc: 0.964652374539\n",
      "Confusion Matrix\n",
      " [[41743   490]\n",
      " [ 1111  1949]]\n",
      "\n",
      "\n",
      "30\n",
      "MCC: 0.695535687047\n",
      "Acc: 0.964652374539\n",
      "Confusion Matrix\n",
      " [[41740   493]\n",
      " [ 1108  1952]]\n"
     ]
    }
   ],
   "source": [
    "models_combo = feat_model_combo()\n",
    "pred_all, trained_models = predict_mixed(models_combo, X_train, y_train, X_test, y_test, False) # Probability True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    rf = RandomForestClassifier(n_estimators=100)\n",
    "    et = ExtraTreesClassifier(n_estimators=100)\n",
    "    xg = xgb.XGBClassifier()\n",
    "    ada = AdaBoostClassifier(base_estimator=et)\n",
    "    gb = GradientBoostingClassifier(n_estimators=100)\n",
    "    lr = LogisticRegression()\n",
    "    \n",
    "    models = {\n",
    "        'rf': rf,\n",
    "        'lr': lr,\n",
    "        'xg': xg,\n",
    "        'et': et,\n",
    "        'gb': gb,\n",
    "        'ada': ada\n",
    "    }\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_uni(models, X_train, y_train, X_test, y_test, prob=False):\n",
    "    preds = DataFrame()\n",
    "    preds['y_true'] = y # Check for y and y_test\n",
    "    \n",
    "    trained_models = {}\n",
    "    \n",
    "    for key, model in models.items():\n",
    "        print('\\n', key)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        trained_models[key] = model\n",
    "        \n",
    "        if prob:\n",
    "            pred = model.predict_proba(X) # Check for X and X_test   \n",
    "            # preds[key+'_0'] = [i[0] for i in pred]\n",
    "            preds[key+'_1'] = [i[1] for i in pred]\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            preds[key] = model.predict(X) # Check for X and X_test       \n",
    "            print('MCC:', matthews_corrcoef(preds['y_true'], preds[key]))\n",
    "            print('Acc:', accuracy_score(preds['y_true'], preds[key]))\n",
    "            print('Confusion Matrix\\n', confusion_matrix(preds['y_true'], preds[key]))\n",
    "    \n",
    "    if prob:\n",
    "        preds.to_excel('uni_ensemble_proba.xlsx', index=False)\n",
    "    else:\n",
    "        preds.to_excel('uni_ensemble_preds.xlsx', index=False)\n",
    "    \n",
    "    return preds, trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = get_models()\n",
    "pred_all, trained_models = predict_uni(models, X_train, y_train, X_test, y_test, True) # Probability True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.651844669685\n",
      "Acc: 0.960612015102\n",
      "Confusion Matrix\n",
      " [[41751   482]\n",
      " [ 1302  1758]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import nanmean\n",
    "\n",
    "pred_all['final'] = pred_all.loc[:,'pred1':'pred40'].apply(lambda row: round(nanmean(row.values)), axis=1)\n",
    "\n",
    "print('MCC:', matthews_corrcoef(pred_all['y_true'], pred_all['final']))\n",
    "print('Acc:', accuracy_score(pred_all['y_true'], pred_all['final']))\n",
    "print('Confusion Matrix\\n', confusion_matrix(pred_all['y_true'], pred_all['final']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred31</th>\n",
       "      <th>pred32</th>\n",
       "      <th>pred33</th>\n",
       "      <th>pred34</th>\n",
       "      <th>pred35</th>\n",
       "      <th>pred36</th>\n",
       "      <th>pred37</th>\n",
       "      <th>pred38</th>\n",
       "      <th>pred39</th>\n",
       "      <th>pred40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_true  pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  \\\n",
       "0       0      0      0      0      0      0      0      0      0      0   \n",
       "1       1      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
       "0   ...         0       0       0       0       0       0       0       0   \n",
       "1   ...         0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pred39  pred40  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "pred_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metalearner on Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
      "0      0      0      0      0      0      0      0      0      0       0   \n",
      "1      0      0      0      0      0      0      0      0      0       0   \n",
      "\n",
      "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
      "0   ...         0       0       0       0       0       0       0       0   \n",
      "1   ...         0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pred39  pred40  \n",
      "0       0       0  \n",
      "1       0       0  \n",
      "\n",
      "[2 rows x 40 columns]\n",
      "\n",
      " (45247, 40) (46, 40)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del pred_all['final']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "y_m = pred_all['y_true']\n",
    "X_m = pred_all.drop('y_true', axis=1)\n",
    "print(X_m.head(2))\n",
    "\n",
    "# Splitting Train test\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(X_m, y_m, stratify=y_m, test_size=0.001, random_state=20)\n",
    "print('\\n', X_train_m.shape, X_test_m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   45.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  24 | elapsed:  1.9min remaining:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:  2.0min remaining:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('model', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'model': [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)]}, {'model':...tropy'], 'model__max_features': ['sqrt'], 'model__min_samples_leaf': [4], 'model__max_depth': [11]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=20)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_pipe = Pipeline([('model', RandomForestClassifier())])\n",
    "meta_grid = GridSearchCV(estimator=meta_pipe, param_grid=model_params, scoring=make_scorer(matthews_corrcoef), verbose=20, n_jobs=-1)\n",
    "meta_grid.fit(X_train_m, y_train_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = meta_grid.best_estimator_.fit(X_train_m, y_train_m)\n",
    "meta_pred = meta_model.predict(X_test_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.855896103236\n",
      "Acc: 0.978260869565\n",
      "Confusion Matrix\n",
      " [[42  1]\n",
      " [ 0  3]]\n"
     ]
    }
   ],
   "source": [
    "print('MCC:', matthews_corrcoef(y_test_m, meta_pred))\n",
    "print('Acc:', accuracy_score(y_test_m, meta_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test_m, meta_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = MLPClassifier((100, 25), max_iter=200,tol=0, verbose=10)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = nn\n",
    "y_pred = best_model.predict(X_test)\n",
    "# print(y_pred[:4])\n",
    "\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Doing gridsearch to find best params configuration\n",
    "clf = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.03],   # Learning rate alpha\n",
    "    'max_depth': [10],   # maximum depth of the tree\n",
    "    'gamma': [0.1, 0.5],   # minimum eval_score deduction at each split\n",
    "    'min_child_weight': [3, 6],  # minimum number of datapoints in a split\n",
    "    'subsample': [0.9],  # sample size row-wise during bootstrap\n",
    "    'colsample_bytree': [0.5],  # column-wise sample size\n",
    "    'n_estimators': [100],   # number of trees to build\n",
    "    }\n",
    "\n",
    "grid = GridSearchCV(clf, params, cv=5, verbose=50, scoring=make_scorer(matthews_corrcoef), n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# CV results\n",
    "cv_result = DataFrame(grid.cv_results_).to_csv('cv_results_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imp_feats = X_train.columns.values[grid.best_params_.get_support(indices=True)]\n",
    "# print(imp_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing on X_test\n",
    "xgb_model = grid.best_estimator_.fit(X_train, y_train) #[imp_feats]\n",
    "y_pred = xgb_model.predict(X_test) #[imp_feats]\n",
    "print('MCC:', matthews_corrcoef(y_test, y_pred))\n",
    "print('Acc:', accuracy_score(y_test, y_pred))\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using best params to find optimum number of iterations\n",
    "grid_output = grid.best_params_\n",
    "params = {\n",
    "    'objective': 'binary:logistic', \n",
    "    #'num_class': 2     # num_class not required with the Binary Logistic\n",
    "    }\n",
    "\n",
    "best_params = {**grid_output, **params}\n",
    "#best_params['learning_rate'] = 0.02\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_xgb = xgb.DMatrix(X_train, y_train)\n",
    "\n",
    "from numpy import linspace, array\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    thresholds = linspace(0.01, 0.99, 50)\n",
    "    mcc = array([matthews_corrcoef(labels, preds>thr) for thr in thresholds])\n",
    "    best_score = mcc.max()\n",
    "    return 'mcc', -best_score\n",
    "\n",
    "cv_results = xgb.cv(best_params, train_xgb, num_boost_round=10000, nfold=5, stratified=True, as_pandas=True, \n",
    "                    seed=1, shuffle=True, early_stopping_rounds=20, feval = evalerror, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nround = cv_results.shape[0]  # Where the best iteration happened\n",
    "print('Best Iteration:', nround)\n",
    "xgb_clf = xgb.train(best_params, train_xgb, num_boost_round=nround, verbose_eval=True)\n",
    "\n",
    "# Predicting on the test set\n",
    "test_xgb  = xgb.DMatrix(test_xgb_org)\n",
    "test_pred = xgb_clf.predict(test_xgb)\n",
    "Class_1, Class_2, Class_3, Class_4, Class_5, Class_6, Class_7, Class_8, Class_9 = map(list, zip(*test_pred))\n",
    "output = DataFrame({'id': test['id'],\n",
    "                    'Class_1': Class_1, \n",
    "                    'Class_2': Class_2, \n",
    "                    'Class_3': Class_3, \n",
    "                    'Class_4': Class_4, \n",
    "                    'Class_5': Class_5, \n",
    "                    'Class_6': Class_6, \n",
    "                    'Class_7': Class_7, \n",
    "                    'Class_8': Class_8, \n",
    "                    'Class_9': Class_9})\n",
    "output = output[['id', 'Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']]\n",
    "\n",
    "output.to_csv('output.csv', index=False)\n",
    "output.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test data Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      PERID  IFATHER  NRCH17_2  IRHHSIZ2  IIHHSIZ2  IRKI17_2  IIKI17_2  \\\n",
      "0  66583679        4       0.0         4         1         2         1   \n",
      "1  35494679        4       0.0         4         1         1         1   \n",
      "\n",
      "   IRHH65_2  IIHH65_2  PRXRETRY  ...    POVERTY3  TOOLONG  TROUBUND  PDEN10  \\\n",
      "0         1         1        99  ...         2.0        2         2       1   \n",
      "1         1         1        99  ...         3.0        2         2       1   \n",
      "\n",
      "   COUTYP2  MAIIN102  AIIND102      ANALWT_C  VESTR  VEREP  \n",
      "0        1         2         2  16346.795400  40020      1  \n",
      "1        1         2         2   3008.863906  40044      2  \n",
      "\n",
      "[2 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "test = read_csv('test.csv', na_values=-1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Feature Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HLNVCOST', 'HLNVOFFR', 'HLNVREF', 'HLNVNEED', 'HLNVSOR']\n",
      "['HLCALLFG', 'HLCALL99']\n",
      ">> Calculating frequency for: IFATHER\n",
      ">> One-hot encoding for: IFATHER\n",
      ">> Calculating frequency for: IIHHSIZ2\n",
      ">> One-hot encoding for: IIHHSIZ2\n",
      ">> Calculating frequency for: IIKI17_2\n",
      ">> One-hot encoding for: IIKI17_2\n",
      ">> Calculating frequency for: IIHH65_2\n",
      ">> One-hot encoding for: IIHH65_2\n",
      ">> Calculating frequency for: PRXRETRY\n",
      ">> One-hot encoding for: PRXRETRY\n",
      ">> Calculating frequency for: PRXYDATA\n",
      ">> One-hot encoding for: PRXYDATA\n",
      ">> Calculating frequency for: MEDICARE\n",
      ">> One-hot encoding for: MEDICARE\n",
      ">> Calculating frequency for: CAIDCHIP\n",
      ">> One-hot encoding for: CAIDCHIP\n",
      ">> Calculating frequency for: CHAMPUS\n",
      ">> One-hot encoding for: CHAMPUS\n",
      ">> Calculating frequency for: PRVHLTIN\n",
      ">> One-hot encoding for: PRVHLTIN\n",
      ">> Calculating frequency for: GRPHLTIN\n",
      ">> One-hot encoding for: GRPHLTIN\n",
      ">> Calculating frequency for: HLTINNOS\n",
      ">> One-hot encoding for: HLTINNOS\n",
      ">> Calculating frequency for: HLCNOTYR\n",
      ">> One-hot encoding for: HLCNOTYR\n",
      ">> Calculating frequency for: HLCNOTMO\n",
      ">> One-hot encoding for: HLCNOTMO\n",
      ">> Calculating frequency for: HLCLAST\n",
      ">> One-hot encoding for: HLCLAST\n",
      ">> Calculating frequency for: HLLOSRSN\n",
      ">> One-hot encoding for: HLLOSRSN\n",
      ">> Calculating frequency for: IRMCDCHP\n",
      ">> One-hot encoding for: IRMCDCHP\n",
      ">> Calculating frequency for: IIMCDCHP\n",
      ">> One-hot encoding for: IIMCDCHP\n",
      ">> Calculating frequency for: IRMEDICR\n",
      ">> One-hot encoding for: IRMEDICR\n",
      ">> Calculating frequency for: IIMEDICR\n",
      ">> One-hot encoding for: IIMEDICR\n",
      ">> Calculating frequency for: IRCHMPUS\n",
      ">> One-hot encoding for: IRCHMPUS\n",
      ">> Calculating frequency for: IICHMPUS\n",
      ">> One-hot encoding for: IICHMPUS\n",
      ">> Calculating frequency for: IRPRVHLT\n",
      ">> One-hot encoding for: IRPRVHLT\n",
      ">> Calculating frequency for: IIPRVHLT\n",
      ">> One-hot encoding for: IIPRVHLT\n",
      ">> Calculating frequency for: IROTHHLT\n",
      ">> One-hot encoding for: IROTHHLT\n",
      ">> Calculating frequency for: IIOTHHLT\n",
      ">> One-hot encoding for: IIOTHHLT\n",
      ">> Calculating frequency for: ANYHLTI2\n",
      ">> One-hot encoding for: ANYHLTI2\n",
      ">> Calculating frequency for: IRINSUR4\n",
      ">> One-hot encoding for: IRINSUR4\n",
      ">> Calculating frequency for: IIINSUR4\n",
      ">> One-hot encoding for: IIINSUR4\n",
      ">> Calculating frequency for: OTHINS\n",
      ">> One-hot encoding for: OTHINS\n",
      ">> Calculating frequency for: CELLNOTCL\n",
      ">> One-hot encoding for: CELLNOTCL\n",
      ">> Calculating frequency for: CELLWRKNG\n",
      ">> One-hot encoding for: CELLWRKNG\n",
      ">> Calculating frequency for: IRFAMSOC\n",
      ">> One-hot encoding for: IRFAMSOC\n",
      ">> Calculating frequency for: IIFAMSOC\n",
      ">> One-hot encoding for: IIFAMSOC\n",
      ">> Calculating frequency for: IRFAMSSI\n",
      ">> One-hot encoding for: IRFAMSSI\n",
      ">> Calculating frequency for: IIFAMSSI\n",
      ">> One-hot encoding for: IIFAMSSI\n",
      ">> Calculating frequency for: IRFSTAMP\n",
      ">> One-hot encoding for: IRFSTAMP\n",
      ">> Calculating frequency for: IIFSTAMP\n",
      ">> One-hot encoding for: IIFSTAMP\n",
      ">> Calculating frequency for: IRFAMPMT\n",
      ">> One-hot encoding for: IRFAMPMT\n",
      ">> Calculating frequency for: IIFAMPMT\n",
      ">> One-hot encoding for: IIFAMPMT\n",
      ">> Calculating frequency for: IRFAMSVC\n",
      ">> One-hot encoding for: IRFAMSVC\n",
      ">> Calculating frequency for: IIFAMSVC\n",
      ">> One-hot encoding for: IIFAMSVC\n",
      ">> Calculating frequency for: IIWELMOS\n",
      ">> One-hot encoding for: IIWELMOS\n",
      ">> Calculating frequency for: IRPINC3\n",
      ">> One-hot encoding for: IRPINC3\n",
      ">> Calculating frequency for: IRFAMIN3\n",
      ">> One-hot encoding for: IRFAMIN3\n",
      ">> Calculating frequency for: IIPINC3\n",
      ">> One-hot encoding for: IIPINC3\n",
      ">> Calculating frequency for: IIFAMIN3\n",
      ">> One-hot encoding for: IIFAMIN3\n",
      ">> Calculating frequency for: GOVTPROG\n",
      ">> One-hot encoding for: GOVTPROG\n",
      ">> Calculating frequency for: POVERTY3\n",
      ">> One-hot encoding for: POVERTY3\n",
      ">> Calculating frequency for: TOOLONG\n",
      ">> One-hot encoding for: TOOLONG\n",
      ">> Calculating frequency for: TROUBUND\n",
      ">> One-hot encoding for: TROUBUND\n",
      ">> Calculating frequency for: PDEN10\n",
      ">> One-hot encoding for: PDEN10\n",
      ">> Calculating frequency for: COUTYP2\n",
      ">> One-hot encoding for: COUTYP2\n",
      ">> Calculating frequency for: MAIIN102\n",
      ">> One-hot encoding for: MAIIN102\n",
      ">> Calculating frequency for: AIIND102\n",
      ">> One-hot encoding for: AIIND102\n",
      ">> Calculating frequency for: VESTR\n",
      ">> One-hot encoding for: VESTR\n",
      ">> Calculating frequency for: VEREP\n",
      ">> One-hot encoding for: VEREP\n",
      ">> Calculating frequency for: HLNV\n",
      ">> One-hot encoding for: HLNV\n",
      ">> Calculating frequency for: HLCALL\n",
      ">> One-hot encoding for: HLCALL\n",
      "   IRKI17_2  IRHH65_2  IRWELMOS      ANALWT_C  NC17  IFATHER_freq  IFATHER_1  \\\n",
      "0         2         1        99  16346.795400   0.0      0.058072          0   \n",
      "1         1         1        99   3008.863906   0.0      0.058072          0   \n",
      "\n",
      "   IFATHER_2  IFATHER_3  IFATHER_4     ...      HLNV_freq  HLNV_15  HLNV_20  \\\n",
      "0          0          0          1     ...       0.067787        0        0   \n",
      "1          0          0          1     ...       0.067787        0        0   \n",
      "\n",
      "   HLNV_25  HLNV_485  HLNV_490  HLNV_495  HLCALL_freq  HLCALL_2  HLCALL_196  \n",
      "0        0         0         0         1     0.067419         0           1  \n",
      "1        0         0         0         1     0.067419         0           1  \n",
      "\n",
      "[2 rows x 317 columns]\n"
     ]
    }
   ],
   "source": [
    "perid = test['PERID']\n",
    "test.drop('PERID', axis=1, inplace=True)\n",
    "\n",
    "from numpy import inf, nan\n",
    "test = test.replace([inf, -inf, nan], 0).fillna(0)\n",
    "\n",
    "test['NC17'] = test['NRCH17_2'] / test['IRHHSIZ2']\n",
    "del test['NRCH17_2']\n",
    "del test['IRHHSIZ2']\n",
    "\n",
    "hlnv_cols = [col for col in test.columns.values if \"HLNV\" in col]\n",
    "print(hlnv_cols)\n",
    "test['HLNV'] = test[hlnv_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlnv_cols, axis=1)\n",
    "\n",
    "hlcall_cols = [col for col in test.columns.values if \"HLCALL\" in col]\n",
    "print(hlcall_cols)\n",
    "test['HLCALL'] = test[hlcall_cols].apply(lambda row: round(sum(row.values)), axis=1)\n",
    "test = test.drop(hlcall_cols, axis=1)\n",
    "\n",
    "test['HLCNOTMO'] = test['HLCNOTMO'].apply(lambda x: 1 if x > 90 else 0)\n",
    "test['HLCLAST'] = test['HLCLAST'].apply(lambda x: 1 if x > 90 else 0)\n",
    "\n",
    "num_cols = ['NC17', 'IRKI17_2', 'IRHH65_2', 'IRWELMOS', 'ANALWT_C']\n",
    "cat_cols = [col for col in test.columns.values if col not in num_cols]\n",
    "\n",
    "for col in cat_cols:\n",
    "    \n",
    "    # Frequency columns\n",
    "    print(f\">> Calculating frequency for: {col}\")\n",
    "    test[col+'_freq'] = test[col].map(freqs[col]['freq'])\n",
    "    \n",
    "    # One Hot Encoding\n",
    "    print(f\">> One-hot encoding for: {col}\")\n",
    "    test[col] = test[col].astype('category',copy=False)\n",
    "    temp = get_dummies(test[col])\n",
    "    temp.columns = [col+'_'+str(i).split('.')[0] for i in temp.columns]\n",
    "    test = test.join(temp)\n",
    "    test = test.drop(col,axis=1)\n",
    "print(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level-1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(0)\n",
    "meta_test = DataFrame()\n",
    "\n",
    "for i, dic in trained_models.items():\n",
    "    meta_test['pred'+str(i)] = dic['model'].predict(test[dic['feats']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "      <th>pred7</th>\n",
       "      <th>pred8</th>\n",
       "      <th>pred9</th>\n",
       "      <th>pred10</th>\n",
       "      <th>...</th>\n",
       "      <th>pred31</th>\n",
       "      <th>pred32</th>\n",
       "      <th>pred33</th>\n",
       "      <th>pred34</th>\n",
       "      <th>pred35</th>\n",
       "      <th>pred36</th>\n",
       "      <th>pred37</th>\n",
       "      <th>pred38</th>\n",
       "      <th>pred39</th>\n",
       "      <th>pred40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "    ...    pred31  pred32  pred33  pred34  pred35  pred36  pred37  pred38  \\\n",
       "0   ...         0       0       0       0       0       0       0       0   \n",
       "1   ...         0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pred39  pred40  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pred1  pred2  pred3  pred4  pred5  pred6  pred7  pred8  pred9  pred10  \\\n",
      "0      0      0      0      0      0      0      0      0      0       0   \n",
      "1      0      0      0      0      0      0      0      0      0       0   \n",
      "\n",
      "     ...     pred33  pred34  pred35  pred36  pred37  pred38  pred39  pred40  \\\n",
      "0    ...          0       0       0       0       0       0       0       0   \n",
      "1    ...          0       0       0       0       0       0       0       0   \n",
      "\n",
      "   Criminal     PERID  \n",
      "0         0  66583679  \n",
      "1         0  35494679  \n",
      "\n",
      "[2 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "meta_test['Criminal'] = meta_model.predict(meta_test)\n",
    "meta_test['PERID'] = perid\n",
    "print(meta_test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_test[['PERID', 'Criminal']].to_csv('final_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criminal  number: 695, percent: 0.06080489938757655\n"
     ]
    }
   ],
   "source": [
    "nc = sum(meta_test['Criminal'])\n",
    "print('Criminal  number: {}, percent: {}'.format(nc, nc / meta_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in imp_feats:\n",
    "    if f not in test.columns.values:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
